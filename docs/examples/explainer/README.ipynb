{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef410d1",
   "metadata": {},
   "source": [
    "# Model Explainer Example\n",
    "\n",
    "![architecture](architecture.png)\n",
    "\n",
    "In this example we will:\n",
    "\n",
    "  * [Describe the project structure](#Project-Structure)\n",
    "  * [Train some models](#Train-Models)\n",
    "  * [Create Tempo artifacts](#Create-Tempo-Artifacts)\n",
    "  * [Run unit tests](#Unit-Tests)\n",
    "  * [Save python environment for our classifier](#Save-Classifier-Environment)\n",
    "  * [Test Locally on Docker](#Test-Locally-on-Docker)\n",
    "  * [Production on Kubernetes via Tempo](#Production-Option-1-(Deploy-to-Kubernetes-with-Tempo))\n",
    "  * [Prodiuction on Kuebrnetes via GitOps](#Production-Option-2-(Gitops))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b5277",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebooks needs to be run in the `tempo-examples` conda environment defined below. Create from project root folder:\n",
    "\n",
    "```bash\n",
    "conda env create --name tempo-examples --file conda/tempo-examples.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ce5e8",
   "metadata": {},
   "source": [
    "## Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ca70f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34martifacts\u001b[00m\r\n",
      "│   ├── \u001b[01;34mexplainer\u001b[00m\r\n",
      "│   └── \u001b[01;34mmodel\u001b[00m\r\n",
      "├── \u001b[01;34mk8s\u001b[00m\r\n",
      "│   └── \u001b[01;34mrbac\u001b[00m\r\n",
      "└── \u001b[01;34msrc\u001b[00m\r\n",
      "    ├── constants.py\r\n",
      "    ├── data.py\r\n",
      "    ├── explainer.py\r\n",
      "    ├── model.py\r\n",
      "    └── tempo.py\r\n",
      "\r\n",
      "6 directories, 5 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree -P \"*.py\"  -I \"__init__.py|__pycache__\" -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dad4f",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "\n",
    " * This section is where as a data scientist you do your work of training models and creating artfacts.\n",
    " * For this example we train sklearn and xgboost classification models for the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c20ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempo.utils import logger\n",
    "import logging\n",
    "import numpy as np\n",
    "import json\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "ARTIFACTS_FOLDER = os.getcwd()+\"/artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa35a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import AdultData\n",
    "data = AdultData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc17ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9656333333333333\n",
      "Test accuracy:  0.854296875\n"
     ]
    }
   ],
   "source": [
    "from src.model import train_model\n",
    "adult_model = train_model(ARTIFACTS_FOLDER, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7afce019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnchorTabular(meta={\n",
       "  'name': 'AnchorTabular',\n",
       "  'type': ['blackbox'],\n",
       "  'explanations': ['local'],\n",
       "  'params': {'disc_perc': (25, 50, 75), 'seed': 1}}\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.explainer import train_explainer\n",
    "train_explainer(ARTIFACTS_FOLDER, data, adult_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396b609",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8345fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tempo import create_tempo_artifacts\n",
    "adult_model, explainer = create_tempo_artifacts(ARTIFACTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0af26",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/tempo.py\n",
    "import os\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "from alibi.utils.wrappers import ArgmaxTransformer\n",
    "from src.constants import EXPLAINER_FOLDER, MODEL_FOLDER\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import PipelineModels\n",
    "from tempo.serve.utils import pipeline, predictmethod\n",
    "\n",
    "\n",
    "def create_tempo_artifacts(artifacts_folder: str) -> Tuple[Model, Any]:\n",
    "    sklearn_model = Model(\n",
    "        name=\"income-sklearn\",\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=f\"{artifacts_folder}/{MODEL_FOLDER}\",\n",
    "        uri=\"gs://seldon-models/test/income/model\",\n",
    "    )\n",
    "\n",
    "    @pipeline(\n",
    "        name=\"income-explainer\",\n",
    "        uri=\"s3://tempo/explainer/pipeline\",\n",
    "        local_folder=f\"{artifacts_folder}/{EXPLAINER_FOLDER}\",\n",
    "        models=PipelineModels(sklearn=sklearn_model),\n",
    "    )\n",
    "    class ExplainerPipeline(object):\n",
    "        def __init__(self):\n",
    "            if \"MLSERVER_MODELS_DIR\" in os.environ:\n",
    "                models_folder = \"\"\n",
    "            else:\n",
    "                models_folder = f\"{artifacts_folder}/{EXPLAINER_FOLDER}\"\n",
    "            with open(models_folder + \"/explainer.dill\", \"rb\") as f:\n",
    "                self.explainer = dill.load(f)\n",
    "            self.ran_init = True\n",
    "\n",
    "        def update_predict_fn(self, x):\n",
    "            if np.argmax(self.models.sklearn(x).shape) == 0:\n",
    "                self.explainer.predictor = self.models.sklearn\n",
    "                self.explainer.samplers[0].predictor = self.models.sklearn\n",
    "            else:\n",
    "                self.explainer.predictor = ArgmaxTransformer(self.models.sklearn)\n",
    "                self.explainer.samplers[0].predictor = ArgmaxTransformer(self.models.sklearn)\n",
    "\n",
    "        @predictmethod\n",
    "        def explain(self, payload: np.ndarray, parameters: dict) -> str:\n",
    "            print(\"Explain called with \", parameters)\n",
    "            if not self.ran_init:\n",
    "                print(\"Loading explainer\")\n",
    "                self.__init__()\n",
    "            self.update_predict_fn(payload)\n",
    "            explanation = self.explainer.explain(payload, **parameters)\n",
    "            return explanation.to_json()\n",
    "\n",
    "    explainer = ExplainerPipeline()\n",
    "    return sklearn_model, explainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc6a4b",
   "metadata": {},
   "source": [
    "## Save Outlier and Svc Environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1f9017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: tempo\r\n",
      "channels:\r\n",
      "  - defaults\r\n",
      "dependencies:\r\n",
      "  - python=3.7.9\r\n",
      "  - pip:\r\n",
      "    - alibi\r\n",
      "    - dill\r\n",
      "    - mlops-tempo @ file:///home/clive/work/mlops/fork-tempo\r\n",
      "    - mlserver==0.3.1.dev7\r\n"
     ]
    }
   ],
   "source": [
    "!cat artifacts/explainer/conda.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c23ab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/clive/anaconda3/envs/tempo-79a239fd-9e5f-4984-ad1a-24bc618b9d4a' to '/home/clive/work/mlops/fork-tempo/docs/examples/explainer/artifacts/explainer/environment.tar.gz'\n",
      "[########################################] | 100% Completed |  1min  6.6s\n"
     ]
    }
   ],
   "source": [
    "from tempo.serve.loader import save\n",
    "save(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a21d5",
   "metadata": {},
   "source": [
    "## Test Locally on Docker\n",
    "\n",
    "Here we test our models using production images but running locally on Docker. This allows us to ensure the final production deployed model will behave as expected when deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a36bfb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "docker_runtime = SeldonDockerRuntime()\n",
    "docker_runtime.deploy(explainer)\n",
    "docker_runtime.wait_ready(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb09a516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain called with  {'threshold': 0.99}\n",
      "['Marital Status = Separated', 'Sex = Female', 'Capital Gain <= 0.00', 'Education = Associates']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(explainer(payload=data.X_test[0:1], parameters={\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22014e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marital Status = Separated', 'Sex = Female', 'Capital Gain <= 0.00', 'Education = Associates', 'Age > 28.00']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(explainer.remote(payload=data.X_test[0:1], parameters={\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c6ea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime.undeploy(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91f4d7",
   "metadata": {},
   "source": [
    "## Production Option 1 (Deploy to Kubernetes with Tempo)\n",
    "\n",
    " * Here we illustrate how to run the final models in \"production\" on Kubernetes by using Tempo to deploy\n",
    " \n",
    "### Prerequisites\n",
    " \n",
    " Create a Kind Kubernetes cluster with Minio and Seldon Core installed using Ansible from the Tempo project Ansible playbook.\n",
    " \n",
    " ```\n",
    " ansible-playbook ansible/playbooks/default.yaml\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8d2fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-secret configured\r\n",
      "serviceaccount/tempo-pipeline unchanged\r\n",
      "role.rbac.authorization.k8s.io/tempo-pipeline unchanged\r\n",
      "rolebinding.rbac.authorization.k8s.io/tempo-pipeline-rolebinding unchanged\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f k8s/rbac -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fa80565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.examples.minio import create_minio_rclone\n",
    "import os\n",
    "create_minio_rclone(os.getcwd()+\"/rclone-minio.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39ff404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.loader import upload\n",
    "upload(adult_model)\n",
    "upload(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c56b5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import RuntimeOptions, KubernetesOptions\n",
    "runtime_options = RuntimeOptions(\n",
    "        k8s_options=KubernetesOptions(\n",
    "            namespace=\"production\",\n",
    "            authSecretName=\"minio-secret\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "363a9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "k8s_runtime = SeldonKubernetesRuntime(runtime_options)\n",
    "k8s_runtime.deploy(explainer)\n",
    "k8s_runtime.wait_ready(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97b59a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Relationship = Unmarried', 'Sex = Female']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(explainer.remote(payload=data.X_test[0:1], parameters={\"threshold\":0.95}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c789f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_runtime.undeploy(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7205b",
   "metadata": {},
   "source": [
    "## Production Option 2 (Gitops)\n",
    "\n",
    " * We create yaml to provide to our DevOps team to deploy to a production cluster\n",
    " * We add Kustomize patches to modify the base Kubernetes yaml created by Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69ee5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "k8s_runtime = SeldonKubernetesRuntime(runtime_options)\n",
    "yaml_str = k8s_runtime.to_k8s_yaml(explainer)\n",
    "with open(os.getcwd()+\"/k8s/tempo.yaml\",\"w\") as f:\n",
    "    f.write(yaml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "748bd754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: machinelearning.seldon.io/v1\n",
      "kind: SeldonDeployment\n",
      "metadata:\n",
      "  name: income-explainer\n",
      "  namespace: production\n",
      "spec:\n",
      "  predictors:\n",
      "  - componentSpecs:\n",
      "    - spec:\n",
      "        containers:\n",
      "        - args: []\n",
      "          env:\n",
      "          - name: MLSERVER_HTTP_PORT\n",
      "            value: \"9000\"\n",
      "          - name: MLSERVER_GRPC_PORT\n",
      "            value: \"9500\"\n",
      "          - name: MLSERVER_MODEL_IMPLEMENTATION\n",
      "            value: tempo.mlserver.InferenceRuntime\n",
      "          - name: MLSERVER_MODEL_NAME\n",
      "            value: income-explainer\n",
      "          - name: MLSERVER_MODEL_URI\n",
      "            value: /mnt/models\n",
      "          - name: TEMPO_RUNTIME_OPTIONS\n",
      "            value: '{\"runtime\": \"tempo.seldon.SeldonKubernetesRuntime\", \"docker_options\":\n",
      "              {\"defaultRuntime\": \"tempo.seldon.SeldonDockerRuntime\"}, \"k8s_options\":\n",
      "              {\"replicas\": 1, \"minReplicas\": null, \"maxReplicas\": null, \"authSecretName\":\n",
      "              \"minio-secret\", \"serviceAccountName\": null, \"defaultRuntime\": \"tempo.seldon.SeldonKubernetesRuntime\",\n",
      "              \"namespace\": \"production\"}, \"ingress_options\": {\"ingress\": \"tempo.ingress.istio.IstioIngress\",\n",
      "              \"ssl\": false, \"verify_ssl\": true}}'\n",
      "          image: seldonio/mlserver:0.3.1.dev7\n",
      "          name: income-explainer\n",
      "          resources:\n",
      "            limits:\n",
      "              cpu: 1\n",
      "              memory: 1Gi\n",
      "            requests:\n",
      "              cpu: 500m\n",
      "              memory: 500Mi\n",
      "    graph:\n",
      "      envSecretRefName: minio-secret\n",
      "      implementation: TRITON_SERVER\n",
      "      modelUri: s3://tempo/explainer/pipeline\n",
      "      name: income-explainer\n",
      "      serviceAccountName: tempo-pipeline\n",
      "      type: MODEL\n",
      "    name: default\n",
      "    replicas: 1\n",
      "  protocol: kfserving\n",
      "---\n",
      "apiVersion: machinelearning.seldon.io/v1\n",
      "kind: SeldonDeployment\n",
      "metadata:\n",
      "  name: income-sklearn\n",
      "  namespace: production\n",
      "spec:\n",
      "  predictors:\n",
      "  - graph:\n",
      "      envSecretRefName: minio-secret\n",
      "      implementation: SKLEARN_SERVER\n",
      "      modelUri: gs://seldon-models/test/income/model\n",
      "      name: income-sklearn\n",
      "      type: MODEL\n",
      "    name: default\n",
      "    replicas: 1\n",
      "  protocol: kfserving\n"
     ]
    }
   ],
   "source": [
    "!kustomize build k8s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
