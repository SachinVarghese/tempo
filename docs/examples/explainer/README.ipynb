{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations Demo with Income Classifier and Alibi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conda env create\n",
    "\n",
    "We create a conda environment for the runtime of our explainer from the `./artifacts/income_explainer/conda.yaml`\n",
    "**This only needs to be done once**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import ModelFramework, KubernetesOptions, RuntimeOptions\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import PipelineModels\n",
    "from tempo.seldon.protocol import SeldonProtocol\n",
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "from tempo.kfserving.protocol import KFServingV2Protocol\n",
    "from tempo.serve.utils import pipeline, predictmethod\n",
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.serve.metadata import ModelFramework, KubernetesOptions\n",
    "from alibi.utils.wrappers import ArgmaxTransformer\n",
    "from tempo.serve.loader import save, upload\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import pprint\n",
    "import dill\n",
    "import json\n",
    "\n",
    "EXPLAINER_FOLDER = f\"{os.getcwd()}/artifacts/income_explainer\"\n",
    "MODEL_FOLDER = f\"{os.getcwd()}/artifacts/income_model\"\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from alibi.explainers import AnchorTabular\n",
    "from alibi.datasets import fetch_adult\n",
    "\n",
    "adult = fetch_adult()\n",
    "data = adult.data\n",
    "target = adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map = adult.category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data_perm = np.random.permutation(np.c_[data, target])\n",
    "data = data_perm[:,:-1]\n",
    "target = data_perm[:,-1]\n",
    "idx = 30000\n",
    "X_train,Y_train = data[:idx,:], target[:idx]\n",
    "X_test, Y_test = data[idx+1:,:], target[idx+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SKLearn Model and Alibi Anchors Tabular Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9656333333333333\n",
      "Test accuracy:  0.854296875\n"
     ]
    }
   ],
   "source": [
    "ordinal_features = [x for x in range(len(feature_names)) if x not in list(category_map.keys())]\n",
    "ordinal_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                      ('scaler', StandardScaler())])\n",
    "categorical_features = list(category_map.keys())\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', ordinal_transformer, ordinal_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features)])\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "model=Pipeline(steps=[(\"preprocess\",preprocessor),(\"model\",clf)])\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(Y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnchorTabular(meta={\n",
       "  'name': 'AnchorTabular',\n",
       "  'type': ['blackbox'],\n",
       "  'explanations': ['local'],\n",
       "  'params': {'disc_perc': [25, 50, 75], 'seed': 1}}\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from alibi.explainers import AnchorTabular\n",
    "predict_fn = lambda x: model.predict(x)\n",
    "explainer = AnchorTabular(predict_fn, feature_names, categorical_names=category_map, seed=1)\n",
    "explainer.fit(X_train, disc_perc=[25, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: Marital Status = Separated AND Sex = Female AND Capital Gain <= 0.00\n",
      "Precision: 0.98\n",
      "Coverage: 0.10\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer.explain(X_test[0], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(model, MODEL_FOLDER+\"/model.joblib\") \n",
    "with open(EXPLAINER_FOLDER+\"/explainer.dill\", 'wb') as f:\n",
    "    dill.dump(explainer,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeOptions=RuntimeOptions(  \n",
    "    k8s_options=KubernetesOptions( \n",
    "        namespace=\"production\",\n",
    "        authSecretName=\"minio-secret\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "sklearn_model = Model(\n",
    "    name=\"income-sklearn\",\n",
    "    platform=ModelFramework.SKLearn,\n",
    "    protocol=SeldonProtocol(),\n",
    "    runtime_options=runtimeOptions,\n",
    "    local_folder=MODEL_FOLDER,\n",
    "    uri=\"gs://seldon-models/test/income/model\"\n",
    ")\n",
    "\n",
    "\n",
    "@pipeline(\n",
    "    name=\"income-explainer\",\n",
    "    uri=\"s3://tempo/explainer/pipeline\",\n",
    "    local_folder=EXPLAINER_FOLDER,\n",
    "    runtime_options=runtimeOptions,\n",
    "    models=PipelineModels(sklearn=sklearn_model)\n",
    ")\n",
    "class ExplainerPipeline(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        if \"MLSERVER_MODELS_DIR\" in os.environ:\n",
    "            models_folder = \"\"\n",
    "        else:\n",
    "            models_folder = EXPLAINER_FOLDER\n",
    "        with open(models_folder+\"/explainer.dill\", \"rb\") as f:\n",
    "            self.explainer = dill.load(f)\n",
    "        self.ran_init = True\n",
    "        \n",
    "    def update_predict_fn(self, x):\n",
    "        if np.argmax(self.models.sklearn(x).shape) == 0:\n",
    "            self.explainer.predictor = self.models.sklearn\n",
    "            self.explainer.samplers[0].predictor = self.models.sklearn\n",
    "        else:\n",
    "            self.explainer.predictor = ArgmaxTransformer(self.models.sklearn)\n",
    "            self.explainer.samplers[0].predictor = ArgmaxTransformer(self.models.sklearn)\n",
    "\n",
    "    @predictmethod\n",
    "    def explain(self, payload: np.ndarray, parameters: dict) -> str:\n",
    "        print(\"Explain called with \", parameters)\n",
    "        if not self.ran_init:\n",
    "            print(\"Loading explainer\")\n",
    "            self.__init__()\n",
    "        self.update_predict_fn(payload)\n",
    "        explanation = self.explainer.explain(payload, **parameters)\n",
    "        return explanation.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PYTHON_VERSION = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "TEMPO_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate artifacts/income_explainer/conda.yaml\n",
    "name: tempo\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python={PYTHON_VERSION}\n",
    "  - pip:\n",
    "    - alibi\n",
    "    - dill\n",
    "    - mlops-tempo @ file://{TEMPO_DIR}\n",
    "    - mlserver==0.3.1.dev7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Saving environment\n",
      "INFO:tempo:Saving tempo model to /home/rskolasinski/work/tempo/docs/examples/explainer/artifacts/income_explainer/model.pickle\n",
      "INFO:tempo:Using found conda.yaml\n",
      "INFO:tempo:Creating conda env with: conda env create --name tempo-e9033460-59b4-45c9-ae39-f3eaea6f903f --file /tmp/tmpqi8yoqze.yml\n",
      "INFO:tempo:packing conda environment from tempo-e9033460-59b4-45c9-ae39-f3eaea6f903f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/rskolasinski/miniconda3/envs/tempo-e9033460-59b4-45c9-ae39-f3eaea6f903f' to '/home/rskolasinski/work/tempo/docs/examples/explainer/artifacts/income_explainer/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 55.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Removing conda env with: conda remove --name tempo-e9033460-59b4-45c9-ae39-f3eaea6f903f --all --yes\n"
     ]
    }
   ],
   "source": [
    "explainer = ExplainerPipeline()\n",
    "save(explainer, save_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy explainer to docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime = SeldonDockerRuntime()\n",
    "docker_runtime.deploy(explainer)\n",
    "docker_runtime.wait_ready(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain called with  {'threshold': 0.99}\n",
      "['Marital Status = Separated', 'Sex = Female', 'Capital Gain <= 0.00', 'Education = Associates']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(explainer(payload=X_test[0:1], parameters={\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marital Status = Separated', 'Sex = Female', 'Capital Gain <= 0.00']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(explainer.remote(payload=X_test[0:1], parameters={\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Undeploying income-explainer\n",
      "INFO:tempo:Undeploying income-sklearn\n"
     ]
    }
   ],
   "source": [
    "docker_runtime.undeploy(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to production on Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Namespace with Minio Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"production\" already exists\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount/tempo-pipeline created\n",
      "role.rbac.authorization.k8s.io/tempo-pipeline created\n",
      "rolebinding.rbac.authorization.k8s.io/tempo-pipeline-rolebinding created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f ../../../k8s/tempo-pipeline-rbac.yaml -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing minio-secret.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile minio-secret.yaml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: minio-secret\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: minioadmin\n",
    "  AWS_SECRET_ACCESS_KEY: minioadmin\n",
    "  AWS_ENDPOINT_URL: http://minio.minio-system.svc.cluster.local:9000\n",
    "  USE_SSL: \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-secret created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f minio-secret.yaml -n production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_IP=!kubectl get svc minio -n minio-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}'\n",
    "MINIO_IP=MINIO_IP[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate rclone.conf\n",
    "[s3]\n",
    "type = s3\n",
    "provider = minio\n",
    "env_auth = false\n",
    "access_key_id = minioadmin\n",
    "secret_access_key = minioadmin\n",
    "endpoint = http://{MINIO_IP}:9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempo.conf import settings\n",
    "settings.rclone_cfg = os.getcwd() + \"/rclone.conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Uploading /home/rskolasinski/work/tempo/docs/examples/explainer/artifacts/income_explainer to s3://tempo/explainer/pipeline\n"
     ]
    }
   ],
   "source": [
    "upload(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_runtime = SeldonKubernetesRuntime()\n",
    "k8s_runtime.deploy(explainer)\n",
    "k8s_runtime.wait_ready(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.utils import tempo_settings\n",
    "tempo_settings.remote_kubernetes(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marital Status = Separated', 'Sex = Female']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(explainer.remote(payload=X_test[0:1], parameters={\"threshold\":0.95}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Undeploying income-explainer\n",
      "INFO:tempo:Undeploying income-sklearn\n"
     ]
    }
   ],
   "source": [
    "k8s_runtime.undeploy(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Gitops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: machinelearning.seldon.io/v1\n",
      "kind: SeldonDeployment\n",
      "metadata:\n",
      "  name: income-explainer\n",
      "  namespace: production\n",
      "spec:\n",
      "  predictors:\n",
      "  - componentSpecs:\n",
      "    - spec:\n",
      "        containers:\n",
      "        - args: []\n",
      "          env:\n",
      "          - name: MLSERVER_HTTP_PORT\n",
      "            value: '9000'\n",
      "          - name: MLSERVER_GRPC_PORT\n",
      "            value: '9500'\n",
      "          - name: MLSERVER_MODEL_IMPLEMENTATION\n",
      "            value: tempo.mlserver.InferenceRuntime\n",
      "          - name: MLSERVER_MODEL_NAME\n",
      "            value: income-explainer\n",
      "          - name: MLSERVER_MODEL_URI\n",
      "            value: /mnt/models\n",
      "          image: seldonio/mlserver:0.3.1.dev7\n",
      "          name: income-explainer\n",
      "    graph:\n",
      "      envSecretRefName: minio-secret\n",
      "      implementation: TRITON_SERVER\n",
      "      modelUri: s3://tempo/explainer/pipeline\n",
      "      name: income-explainer\n",
      "      serviceAccountName: tempo-pipeline\n",
      "      type: MODEL\n",
      "    name: default\n",
      "    replicas: 1\n",
      "  protocol: kfserving\n",
      "\n",
      "---\n",
      "apiVersion: machinelearning.seldon.io/v1\n",
      "kind: SeldonDeployment\n",
      "metadata:\n",
      "  name: income-sklearn\n",
      "  namespace: production\n",
      "spec:\n",
      "  predictors:\n",
      "  - graph:\n",
      "      envSecretRefName: minio-secret\n",
      "      implementation: SKLEARN_SERVER\n",
      "      modelUri: gs://seldon-models/test/income/model\n",
      "      name: income-sklearn\n",
      "      type: MODEL\n",
      "    name: default\n",
      "    replicas: 1\n",
      "  protocol: seldon\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml = k8s_runtime.to_k8s_yaml(explainer)\n",
    "print (eval(pprint.pformat(yaml)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
