{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef410d1",
   "metadata": {},
   "source": [
    "# Model Explainer Example\n",
    "\n",
    "![architecture](architecture.png)\n",
    "\n",
    "In this example we will:\n",
    "\n",
    "  * [Describe the project structure](#Project-Structure)\n",
    "  * [Train some models](#Train-Models)\n",
    "  * [Create Tempo artifacts](#Create-Tempo-Artifacts)\n",
    "  * [Run unit tests](#Unit-Tests)\n",
    "  * [Save python environment for our classifier](#Save-Classifier-Environment)\n",
    "  * [Test Locally on Docker](#Test-Locally-on-Docker)\n",
    "  * [Production on Kubernetes via Tempo](#Production-Option-1-(Deploy-to-Kubernetes-with-Tempo))\n",
    "  * [Prodiuction on Kuebrnetes via GitOps](#Production-Option-2-(Gitops))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b5277",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebooks needs to be run in the `tempo-examples` conda environment defined below. Create from project root folder:\n",
    "\n",
    "```bash\n",
    "conda env create --name tempo-examples --file conda/tempo-examples.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ce5e8",
   "metadata": {},
   "source": [
    "## Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca70f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tree -P \"*.py\"  -I \"__init__.py|__pycache__\" -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dad4f",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "\n",
    " * This section is where as a data scientist you do your work of training models and creating artfacts.\n",
    " * For this example we train sklearn and xgboost classification models for the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c20ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import json\n",
    "import tempo\n",
    "\n",
    "from tempo.utils import logger\n",
    "\n",
    "from src.constants import ARTIFACTS_FOLDER\n",
    "\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import AdultData\n",
    "\n",
    "data = AdultData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc17ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import train_model\n",
    "\n",
    "adult_model = train_model(ARTIFACTS_FOLDER, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afce019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explainer import train_explainer\n",
    "\n",
    "train_explainer(ARTIFACTS_FOLDER, data, adult_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396b609",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8345fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tempo import create_explainer, create_adult_model\n",
    "\n",
    "sklearn_model = create_adult_model()\n",
    "Explainer = create_explainer(sklearn_model)\n",
    "explainer = Explainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0af26",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/tempo.py\n",
    "import os\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "from alibi.utils.wrappers import ArgmaxTransformer\n",
    "from src.constants import ARTIFACTS_FOLDER, EXPLAINER_FOLDER, MODEL_FOLDER\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import PipelineModels\n",
    "from tempo.serve.utils import pipeline, predictmethod\n",
    "\n",
    "\n",
    "def create_adult_model() -> Model :\n",
    "    sklearn_model = Model(\n",
    "        name=\"income-sklearn\",\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=os.path.join(ARTIFACTS_FOLDER, MODEL_FOLDER),\n",
    "        uri=\"gs://seldon-models/test/income/model\",\n",
    "    )\n",
    "\n",
    "    return sklearn_model\n",
    "\n",
    "def create_explainer(model: Model) -> Tuple[Model, Any]:\n",
    "\n",
    "    @pipeline(\n",
    "        name=\"income-explainer\",\n",
    "        uri=\"s3://tempo/explainer/pipeline\",\n",
    "        local_folder=os.path.join(ARTIFACTS_FOLDER, EXPLAINER_FOLDER),\n",
    "        models=PipelineModels(sklearn=model),\n",
    "    )\n",
    "    class ExplainerPipeline(object):\n",
    "        def __init__(self):\n",
    "            pipeline = self.get_tempo()\n",
    "            models_folder = pipeline.details.local_folder\n",
    "\n",
    "            explainer_path = os.path.join(models_folder, \"explainer.dill\")\n",
    "            with open(explainer_path, \"rb\") as f:\n",
    "                self.explainer = dill.load(f)\n",
    "\n",
    "        def update_predict_fn(self, x):\n",
    "            if np.argmax(self.models.sklearn(x).shape) == 0:\n",
    "                self.explainer.predictor = self.models.sklearn\n",
    "                self.explainer.samplers[0].predictor = self.models.sklearn\n",
    "            else:\n",
    "                self.explainer.predictor = ArgmaxTransformer(self.models.sklearn)\n",
    "                self.explainer.samplers[0].predictor = ArgmaxTransformer(self.models.sklearn)\n",
    "\n",
    "        @predictmethod\n",
    "        def explain(self, payload: np.ndarray, parameters: dict) -> str:\n",
    "            print(\"Explain called with \", parameters)\n",
    "            self.update_predict_fn(payload)\n",
    "            explanation = self.explainer.explain(payload, **parameters)\n",
    "            return explanation.to_json()\n",
    "\n",
    "    #explainer = ExplainerPipeline()\n",
    "    #return sklearn_model, explainer\n",
    "    return ExplainerPipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc6a4b",
   "metadata": {},
   "source": [
    "## Save Explainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat artifacts/explainer/conda.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo.save(Explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a21d5",
   "metadata": {},
   "source": [
    "## Test Locally on Docker\n",
    "\n",
    "Here we test our models using production images but running locally on Docker. This allows us to ensure the final production deployed model will behave as expected when deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ade59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo import deploy\n",
    "remote_model = deploy(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = json.loads(remote_model.predict(payload=data.X_test[0:1], parameters={\"threshold\":0.90}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22014e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = json.loads(remote_model.predict(payload=data.X_test[0:1], parameters={\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91f4d7",
   "metadata": {},
   "source": [
    "## Production Option 1 (Deploy to Kubernetes with Tempo)\n",
    "\n",
    " * Here we illustrate how to run the final models in \"production\" on Kubernetes by using Tempo to deploy\n",
    " \n",
    "### Prerequisites\n",
    " \n",
    "Create a Kind Kubernetes cluster with Minio and Seldon Core installed using Ansible as described [here](../../overview/quickstart.md#kubernetes-cluster-with-seldon-core)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f k8s/rbac -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa80565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.examples.minio import create_minio_rclone\n",
    "import os\n",
    "create_minio_rclone(os.getcwd()+\"/rclone-minio.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo.upload(sklearn_model)\n",
    "tempo.upload(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import KubernetesOptions\n",
    "from tempo.seldon.k8s import SeldonCoreOptions\n",
    "runtime_options = SeldonCoreOptions(\n",
    "        k8s_options=KubernetesOptions(\n",
    "            namespace=\"production\",\n",
    "            authSecretName=\"minio-secret\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo import deploy\n",
    "remote_model = deploy(explainer, options=runtime_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b59a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = json.loads(remote_model.predict(payload=data.X_test[0:1], parameters={\"threshold\":0.95}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7205b",
   "metadata": {},
   "source": [
    "## Production Option 2 (Gitops)\n",
    "\n",
    " * We create yaml to provide to our DevOps team to deploy to a production cluster\n",
    " * We add Kustomize patches to modify the base Kubernetes yaml created by Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "\n",
    "k8s_runtime = SeldonKubernetesRuntime(runtime_options)\n",
    "yaml_str = k8s_runtime.manifest(explainer)\n",
    "\n",
    "with open(os.getcwd()+\"/k8s/tempo.yaml\",\"w\") as f:\n",
    "    f.write(yaml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bd754",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kustomize build k8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffbadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
