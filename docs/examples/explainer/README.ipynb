{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conda env create\n",
    "\n",
    "We create a conda environment for the runtime of our explainer from the `./artifacts/income_explainer/conda.yaml`\n",
    "This only needs to be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Ran pip subprocess with arguments:\n",
      "['/home/clive/anaconda3/envs/tempo-explainer-example/bin/python', '-m', 'pip', 'install', '-U', '-r', '/home/clive/work/mlops/fork-tempo/notebooks/artifacts/income_explainer/condaenv.9j0v4jil.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting mlops-tempo\n",
      "  Using cached mlops_tempo-0.1.0.dev4-py3-none-any.whl (38 kB)\n",
      "Collecting alibi\n",
      "  Using cached alibi-0.5.6-py3-none-any.whl (232 kB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Collecting mlserver==0.3.1.dev5\n",
      "  Using cached mlserver-0.3.1.dev5-py3-none-any.whl (45 kB)\n",
      "Collecting mlserver-tempo==0.3.1.dev5\n",
      "  Using cached mlserver_tempo-0.3.1.dev5-py3-none-any.whl (6.4 kB)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-3.15.5-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting grpcio\n",
      "  Using cached grpcio-1.36.1-cp37-cp37m-manylinux2014_x86_64.whl (4.1 MB)\n",
      "Collecting uvicorn\n",
      "  Using cached uvicorn-0.13.4-py3-none-any.whl (46 kB)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.5.1-cp37-cp37m-manylinux2014_x86_64.whl (233 kB)\n",
      "Collecting click\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting fastapi\n",
      "  Using cached fastapi-0.63.0-py3-none-any.whl (50 kB)\n",
      "Collecting scikit-image!=0.17.1,<0.19,>=0.14.2\n",
      "  Using cached scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\n",
      "Collecting matplotlib<4.0.0,>=3.0.0\n",
      "  Using cached matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n",
      "Collecting shap!=0.38.1,<0.39.0,>=0.36.0\n",
      "  Using cached shap-0.37.0-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting numpy<2.0.0,>=1.16.2\n",
      "  Using cached numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
      "Collecting pandas<2.0.0,>=0.23.3\n",
      "  Using cached pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "Collecting spacy[lookups]<4.0.0,>=2.0.0\n",
      "  Using cached spacy-3.0.3-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
      "Collecting requests<3.0.0,>=2.21.0\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting tensorflow<2.5.0,>=2.0.0\n",
      "  Using cached tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
      "Collecting attrs<21.0.0,>=19.2.0\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting typing-extensions>=3.7.2\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting Pillow<9.0,>=5.4.1\n",
      "  Downloading Pillow-8.1.2-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting scikit-learn<0.25.0,>=0.20.2\n",
      "  Using cached scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "Collecting scipy<2.0.0,>=1.1.0\n",
      "  Using cached scipy-1.6.1-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.7.1\n",
      "  Using cached beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.2-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/clive/.local/lib/python3.7/site-packages/cycler-0.10.0-py3.7.egg (from matplotlib<4.0.0,>=3.0.0->alibi->-r /home/clive/work/mlops/fork-tempo/notebooks/artifacts/income_explainer/condaenv.9j0v4jil.requirements.txt (line 2)) (0.10.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting six\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pytz>=2017.3\n",
      "  Using cached pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clive/anaconda3/envs/tempo-explainer-example/lib/python3.7/site-packages (from requests<3.0.0,>=2.21.0->alibi->-r /home/clive/work/mlops/fork-tempo/notebooks/artifacts/income_explainer/condaenv.9j0v4jil.requirements.txt (line 2)) (2020.12.5)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.3-py2.py3-none-any.whl (137 kB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Using cached PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
      "Collecting networkx>=2.0\n",
      "  Using cached networkx-2.5-py3-none-any.whl (1.6 MB)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.3.5-py3-none-any.whl (162 kB)\n",
      "Collecting imageio>=2.3.0\n",
      "  Using cached imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting decorator>=4.3.0\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting numba\n",
      "  Using cached numba-0.52.0-cp37-cp37m-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting slicer==0.0.3\n",
      "  Using cached slicer-0.0.3-py3-none-any.whl (11 kB)\n",
      "Collecting tqdm>4.25.0\n",
      "  Downloading tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.0\n",
      "  Using cached thinc-8.0.1-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
      "Collecting pydantic<1.8.0,>=1.7.1\n",
      "  Using cached pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (126 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Using cached srsly-2.4.0-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
      "  Using cached spacy_legacy-3.0.1-py2.py3-none-any.whl (7.0 kB)\n",
      "Collecting pathy\n",
      "  Using cached pathy-0.4.0-py3-none-any.whl (36 kB)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Using cached typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.8 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (20 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=0.20\n",
      "  Using cached importlib_metadata-3.7.0-py3-none-any.whl (11 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.1\n",
      "  Using cached catalogue-2.0.1-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: setuptools in /home/clive/anaconda3/envs/tempo-explainer-example/lib/python3.7/site-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi->-r /home/clive/work/mlops/fork-tempo/notebooks/artifacts/income_explainer/condaenv.9j0v4jil.requirements.txt (line 2)) (52.0.0.post20210125)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Collecting spacy-lookups-data<1.1.0,>=1.0.0\n",
      "  Using cached spacy_lookups_data-1.0.0-py2.py3-none-any.whl (93.4 MB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting h5py~=2.10.0\n",
      "  Using cached h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting numpy<2.0.0,>=1.16.2\n",
      "  Using cached numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting tensorboard~=2.4\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/clive/anaconda3/envs/tempo-explainer-example/lib/python3.7/site-packages (from tensorflow<2.5.0,>=2.0.0->alibi->-r /home/clive/work/mlops/fork-tempo/notebooks/artifacts/income_explainer/condaenv.9j0v4jil.requirements.txt (line 2)) (0.36.2)\n",
      "Collecting grpcio\n",
      "  Using cached grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.3-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.27.1-py2.py3-none-any.whl (136 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting seldon-deploy-sdk\n",
      "  Using cached seldon_deploy_sdk-0.2.1-py3-none-any.whl (613 kB)\n",
      "Collecting docker\n",
      "  Using cached docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Collecting kubernetes\n",
      "  Using cached kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting conda-pack\n",
      "  Using cached conda_pack-0.5.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting python-rclone\n",
      "  Using cached python_rclone-0.0.2-py3-none-any.whl (4.2 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Using cached websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting starlette==0.13.6\n",
      "  Using cached starlette-0.13.6-py3-none-any.whl (59 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Using cached MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
      "Collecting pyyaml>=3.12\n",
      "  Using cached PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "Collecting llvmlite<0.36,>=0.35.0\n",
      "  Using cached llvmlite-0.35.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Using cached smart_open-3.0.0-py3-none-any.whl\n",
      "Collecting Authlib<=0.16.0\n",
      "  Using cached Authlib-0.15.3-py2.py3-none-any.whl (203 kB)\n",
      "Collecting cryptography\n",
      "  Using cached cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting cffi>=1.12\n",
      "  Using cached cffi-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (402 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "Installing collected packages: zipp, typing-extensions, urllib3, pycparser, pyasn1, importlib-metadata, idna, chardet, six, rsa, requests, pyasn1-modules, oauthlib, numpy, murmurhash, cymem, click, cffi, catalogue, cachetools, wasabi, typer, srsly, smart-open, requests-oauthlib, pyparsing, pydantic, preshed, MarkupSafe, google-auth, cryptography, blis, werkzeug, websocket-client, tqdm, threadpoolctl, thinc, tensorboard-plugin-wit, starlette, spacy-legacy, scipy, pyyaml, pytz, python-dateutil, protobuf, Pillow, pathy, packaging, markdown, llvmlite, kiwisolver, joblib, jinja2, h11, grpcio, google-auth-oauthlib, decorator, Authlib, absl-py, wrapt, uvicorn, tifffile, termcolor, tensorflow-estimator, tensorboard, spacy-lookups-data, spacy, soupsieve, slicer, seldon-deploy-sdk, scikit-learn, PyWavelets, python-rclone, pandas, orjson, opt-einsum, numba, networkx, matplotlib, kubernetes, keras-preprocessing, imageio, h5py, google-pasta, gast, flatbuffers, fastapi, docker, conda-pack, cloudpickle, attrs, astunparse, tensorflow, shap, scikit-image, mlserver, mlops-tempo, beautifulsoup4, mlserver-tempo, dill, alibi\n",
      "Successfully installed Authlib-0.15.3 MarkupSafe-1.1.1 Pillow-8.1.2 PyWavelets-1.1.1 absl-py-0.11.0 alibi-0.5.6 astunparse-1.6.3 attrs-20.3.0 beautifulsoup4-4.9.3 blis-0.7.4 cachetools-4.2.1 catalogue-2.0.1 cffi-1.14.5 chardet-4.0.0 click-7.1.2 cloudpickle-1.6.0 conda-pack-0.5.0 cryptography-3.4.6 cymem-2.0.5 decorator-4.4.2 dill-0.3.3 docker-4.4.4 fastapi-0.63.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.27.1 google-auth-oauthlib-0.4.3 google-pasta-0.2.0 grpcio-1.32.0 h11-0.12.0 h5py-2.10.0 idna-2.10 imageio-2.9.0 importlib-metadata-3.7.0 jinja2-2.11.3 joblib-1.0.1 keras-preprocessing-1.1.2 kiwisolver-1.3.1 kubernetes-12.0.1 llvmlite-0.35.0 markdown-3.3.4 matplotlib-3.3.4 mlops-tempo-0.1.0.dev4 mlserver-0.3.1.dev5 mlserver-tempo-0.3.1.dev5 murmurhash-1.0.5 networkx-2.5 numba-0.52.0 numpy-1.19.5 oauthlib-3.1.0 opt-einsum-3.3.0 orjson-3.5.1 packaging-20.9 pandas-1.2.3 pathy-0.4.0 preshed-3.0.5 protobuf-3.15.5 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20 pydantic-1.7.3 pyparsing-2.4.7 python-dateutil-2.8.1 python-rclone-0.0.2 pytz-2021.1 pyyaml-5.4.1 requests-2.25.1 requests-oauthlib-1.3.0 rsa-4.7.2 scikit-image-0.18.1 scikit-learn-0.24.1 scipy-1.6.1 seldon-deploy-sdk-0.2.1 shap-0.37.0 six-1.15.0 slicer-0.0.3 smart-open-3.0.0 soupsieve-2.2 spacy-3.0.3 spacy-legacy-3.0.1 spacy-lookups-data-1.0.0 srsly-2.4.0 starlette-0.13.6 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 thinc-8.0.1 threadpoolctl-2.1.0 tifffile-2021.3.5 tqdm-4.59.0 typer-0.3.2 typing-extensions-3.7.4.3 urllib3-1.26.3 uvicorn-0.13.4 wasabi-0.8.2 websocket-client-0.58.0 werkzeug-1.0.1 wrapt-1.12.1 zipp-3.4.1\n",
      "\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate tempo-explainer-example\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env create --name tempo-explainer-example --file ./artifacts/income_explainer/conda.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import ModelFramework\n",
    "from tempo.serve.model import Model\n",
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "from tempo.kfserving.protocol import KFServingV2Protocol\n",
    "from tempo.serve.utils import pipeline, predictmethod\n",
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.serve.metadata import ModelFramework, KubernetesOptions\n",
    "from alibi.utils.wrappers import ArgmaxTransformer\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import pprint\n",
    "import dill\n",
    "import json\n",
    "\n",
    "EXPLAINER_FOLDER = os.getcwd()+\"/artifacts/income_explainer\"\n",
    "MODEL_FOLDER = os.getcwd()+\"/artifacts/income_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from alibi.explainers import AnchorTabular\n",
    "from alibi.datasets import fetch_adult\n",
    "\n",
    "adult = fetch_adult()\n",
    "data = adult.data\n",
    "target = adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map = adult.category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data_perm = np.random.permutation(np.c_[data, target])\n",
    "data = data_perm[:,:-1]\n",
    "target = data_perm[:,-1]\n",
    "idx = 30000\n",
    "X_train,Y_train = data[:idx,:], target[:idx]\n",
    "X_test, Y_test = data[idx+1:,:], target[idx+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SKLearn Model and Alibi Anchors Tabular Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9656333333333333\n",
      "Test accuracy:  0.854296875\n"
     ]
    }
   ],
   "source": [
    "ordinal_features = [x for x in range(len(feature_names)) if x not in list(category_map.keys())]\n",
    "ordinal_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                      ('scaler', StandardScaler())])\n",
    "categorical_features = list(category_map.keys())\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', ordinal_transformer, ordinal_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features)])\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "model=Pipeline(steps=[(\"preprocess\",preprocessor),(\"model\",clf)])\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(Y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnchorTabular(meta={\n",
       "  'name': 'AnchorTabular',\n",
       "  'type': ['blackbox'],\n",
       "  'explanations': ['local'],\n",
       "  'params': {'disc_perc': [25, 50, 75], 'seed': 1}}\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from alibi.explainers import AnchorTabular\n",
    "predict_fn = lambda x: model.predict(x)\n",
    "explainer = AnchorTabular(predict_fn, feature_names, categorical_names=category_map, seed=1)\n",
    "explainer.fit(X_train, disc_perc=[25, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: Marital Status = Separated AND Sex = Female AND Capital Gain <= 0.00\n",
      "Precision: 0.98\n",
      "Coverage: 0.10\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer.explain(X_test[0], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(model, MODEL_FOLDER+\"/model.joblib\") \n",
    "with open(EXPLAINER_FOLDER+\"/explainer.dill\", 'wb') as f:\n",
    "    dill.dump(explainer,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_options = KubernetesOptions(namespace=\"production\")\n",
    "k8s_runtime = SeldonKubernetesRuntime(k8s_options=k8s_options)\n",
    "\n",
    "sklearn_model = Model(\n",
    "        name=\"income-sklearn\",\n",
    "        runtime=SeldonDockerRuntime(),\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=MODEL_FOLDER,\n",
    "        uri=\"gs://seldon-models/test/income/model\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@pipeline(name=\"income-explainer\",\n",
    "          runtime=SeldonDockerRuntime(protocol=KFServingV2Protocol()),\n",
    "          uri=\"gs://seldon-models/test/income/explainer\",\n",
    "          local_folder=EXPLAINER_FOLDER,\n",
    "          conda_env=\"tempo-explainer-example\",\n",
    "          models=[sklearn_model])\n",
    "class ExplainerPipeline(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        if \"MLSERVER_MODELS_DIR\" in os.environ:\n",
    "            models_folder = \"\"\n",
    "        else:\n",
    "            models_folder = EXPLAINER_FOLDER\n",
    "        with open(models_folder+\"/explainer.dill\", \"rb\") as f:\n",
    "            self.explainer = dill.load(f)\n",
    "        self.ran_init = True\n",
    "        \n",
    "    def update_predict_fn(self, x):\n",
    "        if np.argmax(sklearn_model(x).shape) == 0:\n",
    "            self.explainer.predictor = sklearn_model\n",
    "            self.explainer.samplers[0].predictor = sklearn_model\n",
    "        else:\n",
    "            self.explainer.predictor = ArgmaxTransformer(sklearn_model)\n",
    "            self.explainer.samplers[0].predictor = ArgmaxTransformer(sklearn_model)\n",
    "\n",
    "    @predictmethod\n",
    "    def explain(self, payload: np.ndarray, parameters: dict) -> str:\n",
    "        print(\"Explain called with \", parameters)\n",
    "        if not self.ran_init:\n",
    "            print(\"Loading explainer\")\n",
    "            self.__init__()\n",
    "        self.update_predict_fn(payload)\n",
    "        explanation = self.explainer.explain(payload, **parameters)\n",
    "        return explanation.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model to Docker and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.deploy()\n",
    "sklearn_model.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9, 0.1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model(X_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create explainer and test against model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ExplainerPipeline() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/clive/anaconda3/envs/tempo-explainer-example' to '/home/clive/work/mlops/fork-tempo/notebooks/artifacts/income_explainer/environment.tar.gz'\n",
      "[########################################] | 100% Completed |  1min  2.8s\n"
     ]
    }
   ],
   "source": [
    "p.save(save_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain called with  {'threshold': 0.95}\n",
      "['Marital Status = Separated', 'Sex = Female']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(p.explain(X_test[0:1], {\"threshold\":0.95}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy explainer to docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.deploy()\n",
    "p.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create v2 from any\n",
      "['Marital Status = Separated', 'Relationship = Unmarried']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(p.remote(payload=X_test[0:1], parameters={\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to production on Kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_options = KubernetesOptions(namespace=\"production\")\n",
    "k8s_runtime = SeldonKubernetesRuntime(k8s_options=k8s_options)\n",
    "k8s_runtime_v2 = SeldonKubernetesRuntime(k8s_options=k8s_options, protocol=KFServingV2Protocol())\n",
    "\n",
    "sklearn_model.set_runtime(k8s_runtime)\n",
    "p.set_runtime(k8s_runtime_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(save_env=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload artifacts. **This step may take some time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.upload()\n",
    "p.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.deploy()\n",
    "p.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create v2 from any\n",
      "['Relationship = Unmarried', 'Sex = Female']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(p.remote(payload=X_test[0:1], parameters={\"threshold\":0.95}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Gitops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: machinelearning.seldon.io/v1\n",
      "kind: SeldonDeployment\n",
      "metadata:\n",
      "  name: income-explainer\n",
      "  namespace: production\n",
      "spec:\n",
      "  predictors:\n",
      "  - componentSpecs:\n",
      "    - spec:\n",
      "        containers:\n",
      "        - args: []\n",
      "          env:\n",
      "          - name: MLSERVER_HTTP_PORT\n",
      "            value: '9000'\n",
      "          - name: MLSERVER_GRPC_PORT\n",
      "            value: '9500'\n",
      "          - name: MLSERVER_MODEL_IMPLEMENTATION\n",
      "            value: mlserver_tempo.TempoModel\n",
      "          - name: MLSERVER_MODEL_NAME\n",
      "            value: income-explainer\n",
      "          - name: MLSERVER_MODEL_URI\n",
      "            value: /mnt/models\n",
      "          image: seldonio/mlserver:0.3.1.dev5\n",
      "          name: income-explainer\n",
      "    graph:\n",
      "      implementation: TRITON_SERVER\n",
      "      modelUri: gs://seldon-models/test/income/explainer\n",
      "      name: income-explainer\n",
      "      serviceAccountName: tempo-pipeline\n",
      "      type: MODEL\n",
      "    name: default\n",
      "    replicas: 1\n",
      "  protocol: kfserving\n",
      "\n",
      "---\n",
      "apiVersion: machinelearning.seldon.io/v1\n",
      "kind: SeldonDeployment\n",
      "metadata:\n",
      "  name: income-sklearn\n",
      "  namespace: production\n",
      "spec:\n",
      "  predictors:\n",
      "  - graph:\n",
      "      implementation: SKLEARN_SERVER\n",
      "      modelUri: gs://seldon-models/test/income/model\n",
      "      name: income-sklearn\n",
      "      type: MODEL\n",
      "    name: default\n",
      "    replicas: 1\n",
      "  protocol: seldon\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml = p.to_k8s_yaml()\n",
    "print (eval(pprint.pformat(yaml)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
