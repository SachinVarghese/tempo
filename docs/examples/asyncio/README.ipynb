{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ambient-chassis",
   "metadata": {},
   "source": [
    "# Leveraging AsyncIO in inference pipelines\n",
    "\n",
    "Tempo includes experimental support for `asyncio`, which provides a way to optimise pipelines.\n",
    "In particular, `asyncio` can be beneficial in scenarios where most of the heavy lifting is done by downstream models and the pipeline just orchestrates calls across these models.\n",
    "In this case, most of the time within the pipeline will be spent waiting for the requests from downstream models to come back.\n",
    "`asyncio` will allow us to process other incoming requests during this waiting time.\n",
    "\n",
    "This example will walk us through the process of setting up an asynchronous pipeline.\n",
    "As you will see, it's quite similar to the usual synchronous pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-candidate",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebooks needs to be run in the `tempo-examples` conda environment defined below. Create from project root folder:\n",
    "\n",
    "```bash\n",
    "conda env create --name tempo-examples --file conda/tempo-examples.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-nepal",
   "metadata": {},
   "source": [
    "## Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neural-darkness",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\n",
      "├── \u001b[01;34martifacts\u001b[00m\n",
      "└── \u001b[01;34msrc\u001b[00m\n",
      "    ├── constants.py\n",
      "    ├── data.py\n",
      "    ├── tempo.py\n",
      "    └── train.py\n",
      "\n",
      "2 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "!tree -P \"*.py\"  -I \"__init__.py|__pycache__\" -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-reggae",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "\n",
    "This section is where as a data scientist you do your work of training models and creating artfacts.\n",
    "For this example, we will train two sklearn and xgboost classification models using the iris dataset.\n",
    "\n",
    "These models will be used by our inference pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "obvious-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tempo.utils import logger\n",
    "\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charged-ethnic",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/train.py\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from src.data import IrisData\n",
    "from src.constants import SKLearnFolder, XGBoostFolder\n",
    "\n",
    "\n",
    "def train_sklearn(data: IrisData):\n",
    "    logreg = LogisticRegression(C=1e5)\n",
    "    logreg.fit(data.X, data.y)\n",
    "\n",
    "    model_path = os.path.join(SKLearnFolder, \"model.joblib\")\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        joblib.dump(logreg, f)\n",
    "\n",
    "\n",
    "def train_xgboost(data: IrisData):\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(data.X, data.y)\n",
    "\n",
    "    model_path = os.path.join(XGBoostFolder, \"model.json\")\n",
    "    clf.save_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "complete-messaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:46] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agm/.virtualenvs/tempo/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from src.data import IrisData\n",
    "from src.train import train_sklearn, train_xgboost\n",
    "\n",
    "data = IrisData()\n",
    "\n",
    "train_sklearn(data)\n",
    "train_xgboost(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-strap",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts\n",
    "\n",
    "Here we create the Tempo models and orchestration Pipeline for our final service using our models.\n",
    "For illustration the final service will call the sklearn model and based on the result will decide to return that prediction or call the xgboost model and return that prediction instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "skilled-wiring",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PipelineModels' from 'tempo' (/home/agm/Seldon/tempo/tempo/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ec42dd1ed0e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtempo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minference_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Seldon/tempo/docs/examples/asyncio/src/tempo.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtempo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelFramework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipelineModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtempo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PipelineModels' from 'tempo' (/home/agm/Seldon/tempo/tempo/__init__.py)"
     ]
    }
   ],
   "source": [
    "from src.tempo import inference_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-carpet",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/tempo.py\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from src.train import SKLearnFolder, XGBoostFolder\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import Pipeline, PipelineModels\n",
    "from tempo.serve.utils import pipeline\n",
    "\n",
    "PipelineFolder = \"classifier\"\n",
    "SKLearnTag = \"sklearn prediction\"\n",
    "XGBoostTag = \"xgboost prediction\"\n",
    "\n",
    "\n",
    "def get_tempo_artifacts(artifacts_folder: str) -> Tuple[Pipeline, Model, Model]:\n",
    "\n",
    "    sklearn_model = Model(\n",
    "        name=\"test-iris-sklearn\",\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=f\"{artifacts_folder}/{SKLearnFolder}\",\n",
    "        uri=\"s3://tempo/basic/sklearn\",\n",
    "        description=\"An SKLearn Iris classification model\",\n",
    "    )\n",
    "\n",
    "    xgboost_model = Model(\n",
    "        name=\"test-iris-xgboost\",\n",
    "        platform=ModelFramework.XGBoost,\n",
    "        local_folder=f\"{artifacts_folder}/{XGBoostFolder}\",\n",
    "        uri=\"s3://tempo/basic/xgboost\",\n",
    "        description=\"An XGBoost Iris classification model\",\n",
    "    )\n",
    "\n",
    "    @pipeline(\n",
    "        name=\"classifier\",\n",
    "        uri=\"s3://tempo/basic/pipeline\",\n",
    "        local_folder=f\"{artifacts_folder}/{PipelineFolder}\",\n",
    "        models=PipelineModels(sklearn=sklearn_model, xgboost=xgboost_model),\n",
    "        description=\"A pipeline to use either an sklearn or xgboost model for Iris classification\",\n",
    "    )\n",
    "    def classifier(payload: np.ndarray) -> Tuple[np.ndarray, str]:\n",
    "        res1 = classifier.models.sklearn(input=payload)\n",
    "\n",
    "        if res1[0] == 1:\n",
    "            return res1, SKLearnTag\n",
    "        else:\n",
    "            return classifier.models.xgboost(input=payload), XGBoostTag\n",
    "\n",
    "    return classifier, sklearn_model, xgboost_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
