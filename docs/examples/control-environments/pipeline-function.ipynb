{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stuffed-wyoming",
   "metadata": {},
   "source": [
    "# Control the runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "outstanding-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-laser",
   "metadata": {},
   "source": [
    "## Train Iris Models\n",
    "\n",
    "We will train:\n",
    "\n",
    "  * A sklearn logistic regression model\n",
    "  * A xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caring-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "determined-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOST_FOLDER = f\"{os.getcwd()}/artifacts/xgboost\"\n",
    "SKLEARN_FOLDER = f\"{os.getcwd()}/artifacts/sklearn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "front-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {XGBOOST_FOLDER}\n",
    "!mkdir -p {SKLEARN_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-tract",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "infinite-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X, y)\n",
    "\n",
    "with open(f\"{SKLEARN_FOLDER}/model.joblib\",\"wb\") as f:\n",
    "    joblib.dump(logreg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thick-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:56:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rskolasinski/miniconda3/envs/tempo-examples/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "clf = xgboost.XGBClassifier()\n",
    "clf.fit(X, y)\n",
    "clf.save_model(f\"{XGBOOST_FOLDER}/model.bst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-netscape",
   "metadata": {},
   "source": [
    "## Write models environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "peaceful-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PYTHON_VERSION = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "SKLEARN_VERSION = sklearn.__version__\n",
    "XGBOOST_VERSION = xgboost.__version__\n",
    "TEMPO_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "packed-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $SKLEARN_FOLDER/conda.yaml\n",
    "name: tempo-sklearn\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python={PYTHON_VERSION}\n",
    "  - pip:\n",
    "    - mlops-tempo @ file://{TEMPO_DIR}\n",
    "    - scikit-learn=={SKLEARN_VERSION}\n",
    "    - mlserver==0.3.1.dev7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "controversial-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $XGBOOST_FOLDER/conda.yaml\n",
    "name: tempo-xgboost\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python={PYTHON_VERSION}\n",
    "  - pip:\n",
    "    - mlops-tempo @ file://{TEMPO_DIR}\n",
    "    - xgboost=={XGBOOST_VERSION}\n",
    "    - mlserver==0.3.1.dev7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-tractor",
   "metadata": {},
   "source": [
    "## Define Model Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "former-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import ModelFramework, KubernetesOptions\n",
    "\n",
    "from tempo.kfserving.protocol import KFServingV2Protocol\n",
    "\n",
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "\n",
    "import tempo.serve.utils as tempo_utils\n",
    "from tempo.serve.loader import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intelligent-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "forward-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "forced-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "import joblib\n",
    "import socket\n",
    "from typing import Tuple\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "@tempo_utils.model(\n",
    "    name=\"sklearn-classifier\",\n",
    "    platform=ModelFramework.TempoPipeline,\n",
    "    uri=\"s3://tempo/control-environments/iris\",\n",
    "    local_folder=SKLEARN_FOLDER,\n",
    ")\n",
    "class IrisClassifier:\n",
    "    def __init__(self):\n",
    "        self.ready = False\n",
    "      \n",
    "    def load(self):\n",
    "        try:\n",
    "            self.model = joblib.load(\"/mnt/models/model.joblib\")        \n",
    "            self.ready = True\n",
    "        except FileNotFoundError:\n",
    "            self.model = joblib.load(f\"{SKLEARN_FOLDER}/model.joblib\")        \n",
    "            self.ready = True\n",
    "\n",
    "    @tempo_utils.predictmethod\n",
    "    def predict(self, payload: np.ndarray) -> dict:\n",
    "        if not self.ready:\n",
    "            self.load()\n",
    "        prediction = self.model.predict_proba(payload)\n",
    "        return {\"prediction\": prediction.tolist(), \"meta\": {\"hostname\": socket.gethostname()}}\n",
    "    \n",
    "    \n",
    "@tempo_utils.model(\n",
    "    name=\"xgboost-classifier\",\n",
    "    platform=ModelFramework.TempoPipeline,\n",
    "    uri=\"s3://tempo/control-environments/xgboost\",\n",
    "    local_folder=XGBOOST_FOLDER,\n",
    ")\n",
    "class XGBoostClassifier:\n",
    "    def __init__(self):\n",
    "        self.ready = False\n",
    "\n",
    "    def load(self):\n",
    "        try:\n",
    "            self.model = xgb.Booster(model_file=\"/mnt/models/model.bst\")\n",
    "            self.ready = True\n",
    "        except (FileNotFoundError, Exception):\n",
    "            self.model = xgb.Booster(model_file=f\"{XGBOOST_FOLDER}/model.bst\")        \n",
    "            self.ready = True            \n",
    "\n",
    "    @tempo_utils.predictmethod\n",
    "    def predict(self, payload: np.ndarray) -> dict:\n",
    "        if not self.ready:\n",
    "            self.load()\n",
    "        prediction = self.model.predict(xgb.DMatrix(payload))\n",
    "        return {\"prediction\": prediction.tolist(), \"meta\": {\"hostname\": socket.gethostname()}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "diverse-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn = IrisClassifier()\n",
    "model_xgboost = XGBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "explicit-comment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Saving environment\n",
      "INFO:tempo:Saving tempo model to /home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/sklearn/model.pickle\n",
      "INFO:tempo:Using found conda.yaml\n",
      "INFO:tempo:Creating conda env with: conda env create --name tempo-22f1967b-26f1-4cb4-b14b-b7feff927e3b --file /tmp/tmp2ryhexn0.yml\n",
      "INFO:tempo:packing conda environment from tempo-22f1967b-26f1-4cb4-b14b-b7feff927e3b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/rskolasinski/miniconda3/envs/tempo-22f1967b-26f1-4cb4-b14b-b7feff927e3b' to '/home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/sklearn/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 15.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Removing conda env with: conda remove --name tempo-22f1967b-26f1-4cb4-b14b-b7feff927e3b --all --yes\n",
      "INFO:tempo:Saving environment\n",
      "INFO:tempo:Saving tempo model to /home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/xgboost/model.pickle\n",
      "INFO:tempo:Using found conda.yaml\n",
      "INFO:tempo:Creating conda env with: conda env create --name tempo-1c0ec134-2e75-4d58-9e0e-b196baa92e96 --file /tmp/tmpsr7e45n3.yml\n",
      "INFO:tempo:packing conda environment from tempo-1c0ec134-2e75-4d58-9e0e-b196baa92e96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/rskolasinski/miniconda3/envs/tempo-1c0ec134-2e75-4d58-9e0e-b196baa92e96' to '/home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/xgboost/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 23.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Removing conda env with: conda remove --name tempo-1c0ec134-2e75-4d58-9e0e-b196baa92e96 --all --yes\n"
     ]
    }
   ],
   "source": [
    "save(model_sklearn, save_env=True)\n",
    "save(model_xgboost, save_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spatial-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime = SeldonDockerRuntime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "round-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker_runtime.undeploy(model_sklearn)\n",
    "# docker_runtime.undeploy(model_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "structural-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime.deploy(model_sklearn)\n",
    "docker_runtime.deploy(model_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incorporated-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p1 = np.array([[1, 2, 3, 4]])\n",
    "p2 = np.array([[5.964,4.006,2.081,1.031]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hollow-publicity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [[9.49810079285076e-34, 2.267015334079471e-19, 1.0]], 'meta': {'hostname': 'machine42'}}\n",
      "{'prediction': [[0.9999999998972331, 1.0276696730328812e-10, 1.633959045505507e-30]], 'meta': {'hostname': 'machine42'}}\n"
     ]
    }
   ],
   "source": [
    "print(model_sklearn(payload=p1))\n",
    "print(model_sklearn(payload=p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adverse-people",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [[9.49810079285076e-34, 2.267015334079471e-19, 1.0]], 'meta': {'hostname': '493ec328bc9b'}}\n",
      "{'prediction': [[0.9999999998972331, 1.0276696730328812e-10, 1.633959045505507e-30]], 'meta': {'hostname': '493ec328bc9b'}}\n"
     ]
    }
   ],
   "source": [
    "print(model_sklearn.remote(payload=p1))\n",
    "print(model_sklearn.remote(payload=p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "printable-first",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [[0.00847206823527813, 0.03168793022632599, 0.9598399996757507]], 'meta': {'hostname': 'machine42'}}\n",
      "{'prediction': [[0.9732961654663086, 0.024121448397636414, 0.002582334913313389]], 'meta': {'hostname': 'machine42'}}\n"
     ]
    }
   ],
   "source": [
    "print(model_xgboost(payload=p1))\n",
    "print(model_xgboost(payload=p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dressed-kruger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [[0.00847206823527813, 0.03168793022632599, 0.9598399996757507]], 'meta': {'hostname': '84ba9adc301a'}}\n",
      "{'prediction': [[0.9732961654663086, 0.024121448397636414, 0.002582334913313389]], 'meta': {'hostname': '84ba9adc301a'}}\n"
     ]
    }
   ],
   "source": [
    "print(model_xgboost.remote(payload=p1))\n",
    "print(model_xgboost.remote(payload=p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-harris",
   "metadata": {},
   "source": [
    "## Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "thrown-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_FOLDER = f\"{os.getcwd()}/artifacts/classifier\"\n",
    "!mkdir -p {PIPELINE_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "inclusive-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.pipeline import PipelineModels\n",
    "from typing import Tuple\n",
    "\n",
    "@tempo_utils.pipeline(\n",
    "    name=\"classifier\",\n",
    "    uri=\"s3://tempo/control-environments/classifier\",\n",
    "    local_folder=PIPELINE_FOLDER,\n",
    "    models=PipelineModels(sklearn=model_sklearn, xgboost=model_xgboost)\n",
    ")\n",
    "def classifier(payload: np.ndarray) -> Tuple[dict, str]:\n",
    "    res1 = classifier.models.sklearn(payload=payload)\n",
    "    if res1[\"prediction\"][0][0] > 0.5:\n",
    "        return res1,\"sklearn prediction\"\n",
    "    else:\n",
    "        return classifier.models.xgboost(payload=payload), \"xgboost prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "advanced-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $PIPELINE_FOLDER/conda.yaml\n",
    "name: tempo\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python={PYTHON_VERSION}\n",
    "  - pip:\n",
    "    - mlops-tempo @ file://{TEMPO_DIR}\n",
    "    - mlserver==0.3.1.dev5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "provincial-documentary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Saving environment\n",
      "INFO:tempo:Saving tempo model to /home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/classifier/model.pickle\n",
      "INFO:tempo:Using found conda.yaml\n",
      "INFO:tempo:Creating conda env with: conda env create --name tempo-84e44dda-496d-4601-a9a5-bdbbd1f47723 --file /tmp/tmpf1tubyyh.yml\n",
      "INFO:tempo:packing conda environment from tempo-84e44dda-496d-4601-a9a5-bdbbd1f47723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/rskolasinski/miniconda3/envs/tempo-84e44dda-496d-4601-a9a5-bdbbd1f47723' to '/home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/classifier/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Removing conda env with: conda remove --name tempo-84e44dda-496d-4601-a9a5-bdbbd1f47723 --all --yes\n"
     ]
    }
   ],
   "source": [
    "save(classifier, save_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "inner-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime.deploy(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "right-thickness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'prediction': [[0.00847206823527813,\n",
       "    0.03168793022632599,\n",
       "    0.9598399996757507]],\n",
       "  'meta': {'hostname': 'machine42'}},\n",
       " 'xgboost prediction')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(payload=p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "optional-cemetery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output0': {'prediction': [[0.00847206823527813,\n",
       "    0.03168793022632599,\n",
       "    0.9598399996757507]],\n",
       "  'meta': {'hostname': '84ba9adc301a'}},\n",
       " 'output1': 'xgboost prediction'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.remote(payload=p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "secret-brief",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Undeploying classifier\n",
      "INFO:tempo:Undeploying sklearn-classifier\n",
      "INFO:tempo:Undeploying xgboost-classifier\n"
     ]
    }
   ],
   "source": [
    "docker_runtime.undeploy(classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
