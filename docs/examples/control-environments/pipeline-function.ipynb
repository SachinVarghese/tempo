{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "steady-addition",
   "metadata": {},
   "source": [
    "# Control the runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spatial-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-yellow",
   "metadata": {},
   "source": [
    "## Train Iris Models\n",
    "\n",
    "We will train:\n",
    "\n",
    "  * A sklearn logistic regression model\n",
    "  * A xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungarian-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laden-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBOOST_FOLDER = f\"{os.getcwd()}/artifacts/xgboost\"\n",
    "SKLEARN_FOLDER = f\"{os.getcwd()}/artifacts/sklearn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wrong-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {XGBOOST_FOLDER}\n",
    "!mkdir -p {SKLEARN_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-component",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southeast-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X, y)\n",
    "\n",
    "with open(f\"{SKLEARN_FOLDER}/model.joblib\",\"wb\") as f:\n",
    "    joblib.dump(logreg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "premium-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:41:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rskolasinski/miniconda3/envs/tempo-examples/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "clf = xgboost.XGBClassifier()\n",
    "clf.fit(X, y)\n",
    "clf.save_model(f\"{XGBOOST_FOLDER}/model.bst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-timeline",
   "metadata": {},
   "source": [
    "## Write models environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "passing-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PYTHON_VERSION = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "SKLEARN_VERSION = sklearn.__version__\n",
    "XGBOOST_VERSION = xgboost.__version__\n",
    "TEMPO_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dimensional-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $SKLEARN_FOLDER/conda.yaml\n",
    "name: tempo-sklearn\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python={PYTHON_VERSION}\n",
    "  - pip:\n",
    "    - mlops-tempo @ file://{TEMPO_DIR}\n",
    "    - scikit-learn=={SKLEARN_VERSION}\n",
    "    - mlserver==0.3.1.dev7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "demanding-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $XGBOOST_FOLDER/conda.yaml\n",
    "name: tempo-xgboost\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python={PYTHON_VERSION}\n",
    "  - pip:\n",
    "    - mlops-tempo @ file://{TEMPO_DIR}\n",
    "    - xgboost=={XGBOOST_VERSION}\n",
    "    - mlserver==0.3.1.dev7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-ordering",
   "metadata": {},
   "source": [
    "## Define Model Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "maritime-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import ModelFramework, KubernetesOptions\n",
    "\n",
    "from tempo.kfserving.protocol import KFServingV2Protocol\n",
    "\n",
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "\n",
    "import tempo.serve.utils as tempo_utils\n",
    "from tempo.serve.loader import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "latter-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hollow-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "opponent-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "import joblib\n",
    "import socket\n",
    "from typing import Tuple\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "@tempo_utils.model(\n",
    "    name=\"sklearn-classifier\",\n",
    "    platform=ModelFramework.TempoPipeline,\n",
    "    uri=\"s3://tempo/control-environments/iris\",\n",
    "    local_folder=SKLEARN_FOLDER,\n",
    ")\n",
    "class IrisClassifier:\n",
    "    def __init__(self):\n",
    "        self.ready = False\n",
    "      \n",
    "    def load(self):\n",
    "        try:\n",
    "            self.model = joblib.load(\"/mnt/models/model.joblib\")        \n",
    "            self.ready = True\n",
    "        except FileNotFoundError:\n",
    "            self.model = joblib.load(f\"{SKLEARN_FOLDER}/model.joblib\")        \n",
    "            self.ready = True\n",
    "\n",
    "    @tempo_utils.predictmethod\n",
    "    def predict(self, payload: np.ndarray) -> dict:\n",
    "        if not self.ready:\n",
    "            self.load()\n",
    "        prediction = self.model.predict_proba(payload)\n",
    "        return {\"prediction\": prediction.tolist(), \"meta\": {\"hostname\": socket.gethostname()}}\n",
    "    \n",
    "    \n",
    "@tempo_utils.model(\n",
    "    name=\"xgboost-classifier\",\n",
    "    platform=ModelFramework.TempoPipeline,\n",
    "    uri=\"s3://tempo/control-environments/xgboost\",\n",
    "    local_folder=XGBOOST_FOLDER,\n",
    ")\n",
    "class XGBoostClassifier:\n",
    "    def __init__(self):\n",
    "        self.ready = False\n",
    "\n",
    "    def load(self):\n",
    "        try:\n",
    "            self.model = xgb.Booster(model_file=\"/mnt/models/model.bst\")\n",
    "            self.ready = True\n",
    "        except (FileNotFoundError, Exception):\n",
    "            self.model = xgb.Booster(model_file=f\"{XGBOOST_FOLDER}/model.bst\")        \n",
    "            self.ready = True            \n",
    "\n",
    "    @tempo_utils.predictmethod\n",
    "    def predict(self, payload: np.ndarray) -> dict:\n",
    "        if not self.ready:\n",
    "            self.load()\n",
    "        prediction = self.model.predict(xgb.DMatrix(payload))\n",
    "        return {\"prediction\": prediction.tolist(), \"meta\": {\"hostname\": socket.gethostname()}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "apparent-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn = IrisClassifier()\n",
    "model_xgboost = XGBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "existing-drunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Saving environment\n",
      "INFO:tempo:Saving tempo model to /home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/sklearn/model.pickle\n",
      "INFO:tempo:Using found conda.yaml\n",
      "INFO:tempo:Creating conda env with: conda env create --name tempo-629dbb30-741d-4dd1-99e6-079e99096cdb --file /tmp/tmp1y01cww0.yml\n",
      "INFO:tempo:packing conda environment from tempo-629dbb30-741d-4dd1-99e6-079e99096cdb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/rskolasinski/miniconda3/envs/tempo-629dbb30-741d-4dd1-99e6-079e99096cdb' to '/home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/sklearn/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Removing conda env with: conda remove --name tempo-629dbb30-741d-4dd1-99e6-079e99096cdb --all --yes\n",
      "INFO:tempo:Saving environment\n",
      "INFO:tempo:Saving tempo model to /home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/xgboost/model.pickle\n",
      "INFO:tempo:Using found conda.yaml\n",
      "INFO:tempo:Creating conda env with: conda env create --name tempo-96d2e059-f3ed-48a8-8edf-b6adde79a6b3 --file /tmp/tmpckw10ltg.yml\n",
      "INFO:tempo:packing conda environment from tempo-96d2e059-f3ed-48a8-8edf-b6adde79a6b3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/rskolasinski/miniconda3/envs/tempo-96d2e059-f3ed-48a8-8edf-b6adde79a6b3' to '/home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/xgboost/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Removing conda env with: conda remove --name tempo-96d2e059-f3ed-48a8-8edf-b6adde79a6b3 --all --yes\n"
     ]
    }
   ],
   "source": [
    "save(model_sklearn, save_env=True)\n",
    "save(model_xgboost, save_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "blank-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime = SeldonDockerRuntime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "irish-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker_runtime.undeploy(model_sklearn)\n",
    "# docker_runtime.undeploy(model_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "elegant-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime.deploy(model_sklearn)\n",
    "docker_runtime.deploy(model_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "designing-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p1 = np.array([[1, 2, 3, 4]])\n",
    "p2 = np.array([[5.964,4.006,2.081,1.031]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "packed-payday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [[9.49810079285076e-34, 2.267015334079471e-19, 1.0]], 'meta': {'hostname': 'machine42'}}\n",
      "{'prediction': [[0.9999999998972331, 1.0276696730328812e-10, 1.633959045505507e-30]], 'meta': {'hostname': 'machine42'}}\n"
     ]
    }
   ],
   "source": [
    "print(model_sklearn(payload=p1))\n",
    "print(model_sklearn(payload=p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "posted-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [[9.49810079285076e-34, 2.267015334079471e-19, 1.0]], 'meta': {'hostname': '28f7558c6543'}}\n",
      "{'prediction': [[0.9999999998972331, 1.0276696730328812e-10, 1.633959045505507e-30]], 'meta': {'hostname': '28f7558c6543'}}\n"
     ]
    }
   ],
   "source": [
    "print(model_sklearn.remote(payload=p1))\n",
    "print(model_sklearn.remote(payload=p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "stock-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [[0.00847206823527813, 0.03168793022632599, 0.9598399996757507]], 'meta': {'hostname': 'machine42'}}\n",
      "{'prediction': [[0.9732961654663086, 0.024121448397636414, 0.002582334913313389]], 'meta': {'hostname': 'machine42'}}\n"
     ]
    }
   ],
   "source": [
    "print(model_xgboost(payload=p1))\n",
    "print(model_xgboost(payload=p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "opened-player",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': [[0.00847206823527813, 0.03168793022632599, 0.9598399996757507]], 'meta': {'hostname': '8e4e2caeec19'}}\n",
      "{'prediction': [[0.9732961654663086, 0.024121448397636414, 0.002582334913313389]], 'meta': {'hostname': '8e4e2caeec19'}}\n"
     ]
    }
   ],
   "source": [
    "print(model_xgboost.remote(payload=p1))\n",
    "print(model_xgboost.remote(payload=p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-basics",
   "metadata": {},
   "source": [
    "## Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acoustic-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_FOLDER = f\"{os.getcwd()}/artifacts/classifier\"\n",
    "!mkdir -p {PIPELINE_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "arabic-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.pipeline import PipelineModels\n",
    "from typing import Tuple\n",
    "\n",
    "@tempo_utils.pipeline(\n",
    "    name=\"classifier\",\n",
    "    uri=\"s3://tempo/control-environments/classifier\",\n",
    "    local_folder=PIPELINE_FOLDER,\n",
    "    models=PipelineModels(sklearn=model_sklearn, xgboost=model_xgboost)\n",
    ")\n",
    "def classifier(payload: np.ndarray) -> Tuple[dict, str]:\n",
    "    res1 = classifier.models.sklearn(payload=payload)\n",
    "    if res1[\"prediction\"][0][0] > 0.5:\n",
    "        return res1,\"sklearn prediction\"\n",
    "    else:\n",
    "        return classifier.models.xgboost(payload=payload), \"xgboost prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "virtual-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate $PIPELINE_FOLDER/conda.yaml\n",
    "name: tempo\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python={PYTHON_VERSION}\n",
    "  - pip:\n",
    "    - mlops-tempo @ file://{TEMPO_DIR}\n",
    "    - mlserver==0.3.1.dev5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "atlantic-stream",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Saving environment\n",
      "INFO:tempo:Saving tempo model to /home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/classifier/model.pickle\n",
      "INFO:tempo:Using found conda.yaml\n",
      "INFO:tempo:Creating conda env with: conda env create --name tempo-d10d1874-a3eb-4274-bbe1-143501c28dad --file /tmp/tmp774j81rk.yml\n",
      "INFO:tempo:packing conda environment from tempo-d10d1874-a3eb-4274-bbe1-143501c28dad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/rskolasinski/miniconda3/envs/tempo-d10d1874-a3eb-4274-bbe1-143501c28dad' to '/home/rskolasinski/work/tempo/docs/examples/control-environments/artifacts/classifier/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Removing conda env with: conda remove --name tempo-d10d1874-a3eb-4274-bbe1-143501c28dad --all --yes\n"
     ]
    }
   ],
   "source": [
    "save(classifier, save_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "minute-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime.deploy(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "reflected-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'prediction': [[0.00847206823527813,\n",
       "    0.03168793022632599,\n",
       "    0.9598399996757507]],\n",
       "  'meta': {'hostname': 'machine42'}},\n",
       " 'xgboost prediction')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(payload=p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "common-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output0': {'prediction': [[0.00847206823527813,\n",
       "    0.03168793022632599,\n",
       "    0.9598399996757507]],\n",
       "  'meta': {'hostname': '8e4e2caeec19'}},\n",
       " 'output1': 'xgboost prediction'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.remote(payload=p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "static-specification",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Undeploying classifier\n",
      "INFO:tempo:Undeploying sklearn-classifier\n",
      "INFO:tempo:Undeploying xgboost-classifier\n"
     ]
    }
   ],
   "source": [
    "docker_runtime.undeploy(classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
