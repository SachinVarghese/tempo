{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "certain-chest",
   "metadata": {},
   "source": [
    "# Basic Tempo Example\n",
    "\n",
    "This notebook will walk you through an end-to-end example deploying a Tempo pipeline, running on its own Conda environment.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "  * Tempo prerequisites rclone and conda installed.\n",
    "  * Run this notebook within the `seldon-examples` conda environment. Details to create this can be found [here]()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-vegetarian",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "We will show two Iris dataset prediction models combined with service orchestration that shows some arbitrary python code to control predictions from the two models.\n",
    "\n",
    "![architecture](architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-replication",
   "metadata": {},
   "source": [
    "## Train Iris Models\n",
    "\n",
    "We will train:\n",
    "\n",
    "  * A sklearn logistic regression model\n",
    "  * A xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we only take the first two features.\n",
    "y = iris.target\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X, y)\n",
    "logreg.predict_proba(X[0:1])\n",
    "with open(\"./artifacts/sklearn/model.joblib\",\"wb\") as f:\n",
    "    joblib.dump(logreg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X,y)\n",
    "clf.save_model(\"./artifacts/xgboost/model.bst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-absolute",
   "metadata": {},
   "source": [
    "## Defining pipeline\n",
    "\n",
    "The first step will be to define our custom pipeline.\n",
    "This pipeline will access 2 models, stored remotely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from tempo.serve.metadata import ModelFramework, KubernetesOptions\n",
    "from tempo.serve.model import Model\n",
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "from tempo.kfserving.protocol import KFServingV2Protocol\n",
    "from tempo.serve.utils import pipeline, predictmethod\n",
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.serve.utils import pipeline\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "SKLEARN_FOLDER = os.getcwd()+\"/artifacts/sklearn\"\n",
    "XGBOOST_FOLDER = os.getcwd()+\"/artifacts/xgboost\"\n",
    "PIPELINE_ARTIFACTS_FOLDER = os.getcwd()+\"/artifacts/classifier\"\n",
    "\n",
    "docker_runtime = SeldonDockerRuntime()\n",
    "\n",
    "sklearn_model = Model(\n",
    "        name=\"test-iris-sklearn\",\n",
    "        runtime=docker_runtime,\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=SKLEARN_FOLDER,\n",
    "        uri=\"s3://tempo/basic/sklearn\"\n",
    ")\n",
    "\n",
    "xgboost_model = Model(\n",
    "        name=\"test-iris-xgboost\",\n",
    "        runtime=docker_runtime,\n",
    "        platform=ModelFramework.XGBoost,\n",
    "        local_folder=XGBOOST_FOLDER,\n",
    "        uri=\"s3://tempo/basic/xgboost\"\n",
    ")\n",
    "\n",
    "docker_runtime_v2 = SeldonDockerRuntime(protocol=KFServingV2Protocol())\n",
    "\n",
    "@pipeline(name=\"classifier\",\n",
    "          runtime=docker_runtime_v2,\n",
    "          uri=\"s3://tempo/basic/pipeline\",\n",
    "          local_folder=PIPELINE_ARTIFACTS_FOLDER,\n",
    "          models=[sklearn_model, xgboost_model])\n",
    "def classifier(payload: np.ndarray) -> Tuple[np.ndarray,str]:\n",
    "    res1 = sklearn_model(payload)\n",
    "\n",
    "    if res1[0][0] > 0.5:\n",
    "        return res1,\"sklearn prediction\"\n",
    "    else:\n",
    "        return xgboost_model(payload),\"xgboost prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-variation",
   "metadata": {},
   "source": [
    "## Deploying pipeline to Docker\n",
    "\n",
    "The next step, will be to deploy our pipeline to Docker.\n",
    "We will divide this process into 2 steps:\n",
    "\n",
    "1. Save our artifacts and environment\n",
    "2. Deploy resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-pacific",
   "metadata": {},
   "source": [
    "### Saving artifacts\n",
    "\n",
    "We provide a conda yaml in out `local_folder` which tempo will use as the runtime environment to save. If this file was not there it would save the current conda environment. One can also provide a named conda environment with `conda_env` in the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile artifacts/classifier/conda.yaml\n",
    "name: tempo\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - _libgcc_mutex=0.1=main\n",
    "  - ca-certificates=2021.1.19=h06a4308_0\n",
    "  - certifi=2020.12.5=py37h06a4308_0\n",
    "  - ld_impl_linux-64=2.33.1=h53a641e_7\n",
    "  - libedit=3.1.20191231=h14c3975_1\n",
    "  - libffi=3.3=he6710b0_2\n",
    "  - libgcc-ng=9.1.0=hdf63c60_0\n",
    "  - libstdcxx-ng=9.1.0=hdf63c60_0\n",
    "  - ncurses=6.2=he6710b0_1\n",
    "  - openssl=1.1.1j=h27cfd23_0\n",
    "  - pip=21.0.1=py37h06a4308_0\n",
    "  - python=3.7.9=h7579374_0\n",
    "  - readline=8.1=h27cfd23_0\n",
    "  - setuptools=52.0.0=py37h06a4308_0\n",
    "  - sqlite=3.33.0=h62c20be_0\n",
    "  - tk=8.6.10=hbc83047_0\n",
    "  - wheel=0.36.2=pyhd3eb1b0_0\n",
    "  - xz=5.2.5=h7b6447c_0\n",
    "  - zlib=1.2.11=h7b6447c_3\n",
    "  - pip:\n",
    "    - mlops-tempo\n",
    "    - mlserver==0.3.1.dev5\n",
    "    - mlserver-tempo==0.3.1.dev5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(save_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-sperm",
   "metadata": {},
   "source": [
    "### Deploying pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-gasoline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.deploy()\n",
    "classifier.wait_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-tucson",
   "metadata": {},
   "source": [
    "### Sending requests\n",
    "\n",
    "We can send requests to the deployed components with either the python code for the classifier running locally or remotely. \n",
    "\n",
    "First we test calling the classifer locally. It will call out to the remote models running in Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(payload=np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-stomach",
   "metadata": {},
   "source": [
    "Now we can use the `.remote` method to call to the remote classifier running in Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.remote(payload=np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.remote(payload=np.array([[5.964,4.006,2.081,1.031]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-orange",
   "metadata": {},
   "source": [
    "### Undeploy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-translator",
   "metadata": {},
   "source": [
    "## Deploying pipeline to K8s\n",
    "\n",
    "The next step, will be to deploy our pipeline to Kubernetes.\n",
    "We will divide this process into 3 sub-steps:\n",
    "\n",
    "1. Save our artifacts and environment\n",
    "2. Upload to remote storage\n",
    "3. Deploy resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-presentation",
   "metadata": {},
   "source": [
    "### Setup Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create namespace production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f ../../../k8s/tempo-pipeline-rbac.yaml -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile minio-secret.yaml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: minio-secret\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: minioadmin\n",
    "  AWS_SECRET_ACCESS_KEY: minioadmin\n",
    "  AWS_ENDPOINT_URL: http://minio.minio-system.svc.cluster.local:9000\n",
    "  USE_SSL: \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f minio-secret.yaml -n production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-valuation",
   "metadata": {},
   "source": [
    "### Change runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_options = KubernetesOptions(namespace=\"production\",authSecretName=\"minio-secret\")\n",
    "\n",
    "k8s_runtime = SeldonKubernetesRuntime(k8s_options=k8s_options)\n",
    "sklearn_model.set_runtime(k8s_runtime)\n",
    "xgboost_model.set_runtime(k8s_runtime)\n",
    "\n",
    "k8s_runtime_v2 = SeldonKubernetesRuntime(k8s_options=k8s_options, protocol=KFServingV2Protocol())\n",
    "classifier.set_runtime(k8s_runtime_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-azerbaijan",
   "metadata": {},
   "source": [
    "### Saving artifacts\n",
    "\n",
    "Just save the artfacts and not the environment as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(save_env=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-worry",
   "metadata": {},
   "source": [
    "### Uploading artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_IP=!kubectl get svc minio -n minio-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}'\n",
    "MINIO_IP=MINIO_IP[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate rclone.conf\n",
    "[s3]\n",
    "type = s3\n",
    "provider = minio\n",
    "env_auth = false\n",
    "access_key_id = minioadmin\n",
    "secret_access_key = minioadmin\n",
    "endpoint = http://{MINIO_IP}:9000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempo.conf import settings\n",
    "settings.rclone_cfg = os.getcwd() + \"/rclone.conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.upload()\n",
    "xgboost_model.upload()\n",
    "classifier.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-arizona",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.deploy()\n",
    "classifier.wait_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-listing",
   "metadata": {},
   "source": [
    "### Sending requests\n",
    "\n",
    "Lastly, we can now send requests to our deployed pipeline.\n",
    "For this, we will leverage the `remote()` method, which will interact without our deployed pipeline (as opposed to executing our pipeline's code locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.remote(payload=np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-warehouse",
   "metadata": {},
   "source": [
    "### Undeploy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-expense",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
