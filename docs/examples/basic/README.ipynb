{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "certain-chest",
   "metadata": {},
   "source": [
    "# Basic Tempo Example\n",
    "\n",
    "This notebook will walk you through an end-to-end example deploying a Tempo pipeline, running on its own Conda environment.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Run this notebook within the `seldon-examples` conda environment. Details to create this can be found [here]()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-vegetarian",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "We will show two Iris dataset prediction models combined with service orchestration that shows some arbitrary python code to control predictions from the two models.\n",
    "\n",
    "![architecture](architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complimentary-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-inflation",
   "metadata": {},
   "source": [
    "## Train Iris Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-absolute",
   "metadata": {},
   "source": [
    "## Defining pipeline\n",
    "\n",
    "The first step will be to define our custom pipeline.\n",
    "This pipeline will access 2 models, stored remotely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "honest-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework, KubernetesOptions\n",
    "from tempo.serve.model import Model\n",
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "from tempo.kfserving.protocol import KFServingV2Protocol\n",
    "from tempo.serve.utils import pipeline, predictmethod\n",
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.serve.utils import pipeline\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "SKLEARN_FOLDER = os.getcwd()+\"/artifacts/sklearn\"\n",
    "XGBOOST_FOLDER = os.getcwd()+\"/artifacts/xgboost\"\n",
    "PIPELINE_ARTIFACTS_FOLDER = os.getcwd()+\"/artifacts/classifier\"\n",
    "\n",
    "docker_runtime = SeldonDockerRuntime()\n",
    "\n",
    "sklearn_model = Model(\n",
    "        name=\"test-iris-sklearn\",\n",
    "        runtime=docker_runtime,\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=SKLEARN_FOLDER,\n",
    "        uri=\"gs://seldon-models/sklearn/iris\"\n",
    ")\n",
    "\n",
    "xgboost_model = Model(\n",
    "        name=\"test-iris-xgboost\",\n",
    "        runtime=docker_runtime,\n",
    "        platform=ModelFramework.XGBoost,\n",
    "        local_folder=XGBOOST_FOLDER,\n",
    "        uri=\"gs://seldon-models/xgboost/iris\"\n",
    ")\n",
    "\n",
    "docker_runtime_v2 = SeldonDockerRuntime(protocol=KFServingV2Protocol())\n",
    "\n",
    "@pipeline(name=\"classifier\",\n",
    "          runtime=docker_runtime_v2,\n",
    "          uri=\"s3://tempo/basic/pipeline\",\n",
    "          local_folder=PIPELINE_ARTIFACTS_FOLDER,\n",
    "          models=[sklearn_model, xgboost_model])\n",
    "def classifier(payload: np.ndarray) -> np.ndarray:\n",
    "    res1 = sklearn_model(payload)\n",
    "\n",
    "    if res1[0][0] > 0.5:\n",
    "        return res1\n",
    "    else:\n",
    "        return xgboost_model(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-variation",
   "metadata": {},
   "source": [
    "## Deploying pipeline to Docker\n",
    "\n",
    "The next step, will be to deploy our pipeline to Docker.\n",
    "We will divide this process into 3 sub-steps:\n",
    "\n",
    "1. Save our artifacts and environment\n",
    "2. Download our model artifacts locally\n",
    "3. Deploy resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-pacific",
   "metadata": {},
   "source": [
    "### Saving artifacts\n",
    "\n",
    "We provide a conda yaml in out `local_folder` which tempo will use as the runtime environment to save. If this file was not there it would save the current conda environment. One can also provide a named conda environment with `conda_env` in the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile artifacts/classifier/conda.yaml\n",
    "name: tempo\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - _libgcc_mutex=0.1=main\n",
    "  - ca-certificates=2021.1.19=h06a4308_0\n",
    "  - certifi=2020.12.5=py37h06a4308_0\n",
    "  - ld_impl_linux-64=2.33.1=h53a641e_7\n",
    "  - libedit=3.1.20191231=h14c3975_1\n",
    "  - libffi=3.3=he6710b0_2\n",
    "  - libgcc-ng=9.1.0=hdf63c60_0\n",
    "  - libstdcxx-ng=9.1.0=hdf63c60_0\n",
    "  - ncurses=6.2=he6710b0_1\n",
    "  - openssl=1.1.1j=h27cfd23_0\n",
    "  - pip=21.0.1=py37h06a4308_0\n",
    "  - python=3.7.9=h7579374_0\n",
    "  - readline=8.1=h27cfd23_0\n",
    "  - setuptools=52.0.0=py37h06a4308_0\n",
    "  - sqlite=3.33.0=h62c20be_0\n",
    "  - tk=8.6.10=hbc83047_0\n",
    "  - wheel=0.36.2=pyhd3eb1b0_0\n",
    "  - xz=5.2.5=h7b6447c_0\n",
    "  - zlib=1.2.11=h7b6447c_3\n",
    "  - pip:\n",
    "    - mlops-tempo\n",
    "    - mlserver==0.3.1.dev5\n",
    "    - mlserver-tempo==0.3.1.dev5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-payday",
   "metadata": {},
   "source": [
    "### Downloading model artifacts\n",
    "\n",
    "Since we are going to deploy our pipeline locally using Docker, we'll need to download the model artifacts locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-measurement",
   "metadata": {},
   "source": [
    "### Configure rclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile rclone.conf\n",
    "[gs]\n",
    "type = google cloud storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempo.conf import settings\n",
    "settings.rclone_cfg = os.getcwd() + \"/rclone.conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.download()\n",
    "xgboost_model.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-sperm",
   "metadata": {},
   "source": [
    "### Deploying pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.deploy()\n",
    "classifier.wait_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-tucson",
   "metadata": {},
   "source": [
    "### Sending requests\n",
    "\n",
    "Lastly, we can now send requests to our deployed pipeline.\n",
    "For this, we will leverage the `remote()` method, which will interact without our deployed pipeline (as opposed to executing our pipeline's code locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.remote(payload=np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-orange",
   "metadata": {},
   "source": [
    "### Undeploy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-translator",
   "metadata": {},
   "source": [
    "## Deploying pipeline to K8s\n",
    "\n",
    "The next step, will be to deploy our pipeline to Kubernetes.\n",
    "We will divide this process into 3 sub-steps:\n",
    "\n",
    "1. Save our artifacts and environment\n",
    "2. Upload to remote storage\n",
    "3. Deploy resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-certification",
   "metadata": {},
   "source": [
    "### Setup Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create namespace production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exempt-burton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount/tempo-pipeline created\n",
      "role.rbac.authorization.k8s.io/tempo-pipeline created\n",
      "rolebinding.rbac.authorization.k8s.io/tempo-pipeline-rolebinding created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f ../../../k8s/tempo-pipeline-rbac.yaml -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "perfect-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing minio-secret.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile minio-secret.yaml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: minio-secret\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: minioadmin\n",
    "  AWS_SECRET_ACCESS_KEY: minioadmin\n",
    "  AWS_ENDPOINT_URL: http://minio.minio-system.svc.cluster.local:9000\n",
    "  USE_SSL: \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "devoted-carroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-secret created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f minio-secret.yaml -n production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-valuation",
   "metadata": {},
   "source": [
    "### Change runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conscious-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_options = KubernetesOptions(namespace=\"production\",authSecretName=\"minio-secret\")\n",
    "\n",
    "k8s_runtime = SeldonKubernetesRuntime(k8s_options=k8s_options)\n",
    "sklearn_model.set_runtime(k8s_runtime)\n",
    "xgboost_model.set_runtime(k8s_runtime)\n",
    "\n",
    "k8s_runtime_v2 = SeldonKubernetesRuntime(k8s_options=k8s_options, protocol=KFServingV2Protocol())\n",
    "classifier.set_runtime(k8s_runtime_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-azerbaijan",
   "metadata": {},
   "source": [
    "### Saving artifacts\n",
    "\n",
    "Just save the artfacts and not the environment as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "billion-spine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving environment\n"
     ]
    }
   ],
   "source": [
    "classifier.save(save_env=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-worry",
   "metadata": {},
   "source": [
    "### Uploading artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "durable-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_IP=!kubectl get svc minio -n minio-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}'\n",
    "MINIO_IP=MINIO_IP[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "peripheral-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate rclone.conf\n",
    "[s3]\n",
    "type = s3\n",
    "provider = minio\n",
    "env_auth = false\n",
    "access_key_id = minioadmin\n",
    "secret_access_key = minioadmin\n",
    "endpoint = http://{MINIO_IP}:9000\n",
    "        \n",
    "[gs]\n",
    "type = google cloud storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "popular-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempo.conf import settings\n",
    "settings.rclone_cfg = os.getcwd() + \"/rclone.conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "essential-south",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Uploading /home/clive/work/mlops/fork-tempo/docs/examples/basic/artifacts/classifier to s3://tempo/basic/pipeline\n"
     ]
    }
   ],
   "source": [
    "classifier.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-arizona",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "scenic-token",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Deploying test-iris-sklearn\n",
      "INFO:tempo:Deploying test-iris-xgboost\n",
      "INFO:tempo:Deploying classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.deploy()\n",
    "classifier.wait_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-listing",
   "metadata": {},
   "source": [
    "### Sending requests\n",
    "\n",
    "Lastly, we can now send requests to our deployed pipeline.\n",
    "For this, we will leverage the `remote()` method, which will interact without our deployed pipeline (as opposed to executing our pipeline's code locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "federal-insulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.remote(payload=np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-warehouse",
   "metadata": {},
   "source": [
    "### Undeploy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "narrative-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Undeploying classifier\n",
      "INFO:tempo:Undeploying test-iris-sklearn\n",
      "INFO:tempo:Undeploying test-iris-xgboost\n"
     ]
    }
   ],
   "source": [
    "classifier.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-workshop",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
