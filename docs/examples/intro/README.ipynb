{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef410d1",
   "metadata": {},
   "source": [
    "# Tempo Introduction\n",
    "\n",
    "![architecture](architecture.png)\n",
    "\n",
    "In this introduction we will:\n",
    "\n",
    "  * [Describe the project structure](#Project-Structure)\n",
    "  * [Train some models](#Train-Models)\n",
    "  * [Create Tempo artifacts](#Create-Tempo-Artifacts)\n",
    "  * [Run unit tests](#Unit-Tests)\n",
    "  * [Save python environment for our classifier](#Save-Classifier-Environment)\n",
    "  * [Test Locally on Docker](#Test-Locally-on-Docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b5277",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebooks needs to be run in the `tempo-examples` conda environment defined below. Create from project root folder:\n",
    "\n",
    "```bash\n",
    "conda env create --name tempo-examples --file conda/tempo-examples.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ce5e8",
   "metadata": {},
   "source": [
    "## Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8ca70f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34martifacts\u001b[00m\r\n",
      "│   ├── \u001b[01;34mclassifier\u001b[00m\r\n",
      "│   ├── \u001b[01;34msklearn\u001b[00m\r\n",
      "│   └── \u001b[01;34mxgboost\u001b[00m\r\n",
      "├── \u001b[01;34mk8s\u001b[00m\r\n",
      "│   └── \u001b[01;34mrbac\u001b[00m\r\n",
      "├── \u001b[01;34msrc\u001b[00m\r\n",
      "│   ├── data.py\r\n",
      "│   ├── tempo.py\r\n",
      "│   └── train.py\r\n",
      "└── \u001b[01;34mtests\u001b[00m\r\n",
      "    └── test_tempo.py\r\n",
      "\r\n",
      "8 directories, 4 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree -P \"*.py\"  -I \"__init__.py|__pycache__\" -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dad4f",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "\n",
    " * This section is where as a data scientist you do your work of training models and creating artfacts.\n",
    " * For this example we train sklearn and xgboost classification models for the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c20ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempo.utils import logger\n",
    "import logging\n",
    "import numpy as np\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "ARTIFACTS_FOLDER = os.getcwd()+\"/artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2abd28",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/train.py\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from src.data import IrisData\n",
    "\n",
    "SKLearnFolder = \"sklearn\"\n",
    "XGBoostFolder = \"xgboost\"\n",
    "\n",
    "\n",
    "def train_sklearn(data: IrisData, artifacts_folder: str):\n",
    "    logreg = LogisticRegression(C=1e5)\n",
    "    logreg.fit(data.X, data.y)\n",
    "    with open(f\"{artifacts_folder}/{SKLearnFolder}/model.joblib\", \"wb\") as f:\n",
    "        joblib.dump(logreg, f)\n",
    "\n",
    "\n",
    "def train_xgboost(data: IrisData, artifacts_folder: str):\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(data.X, data.y)\n",
    "    clf.save_model(f\"{artifacts_folder}/{XGBoostFolder}/model.bst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa35a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:09:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clive/anaconda3/envs/tempo-examples/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from src.data import IrisData\n",
    "from src.train import train_sklearn, train_xgboost\n",
    "data = IrisData()\n",
    "train_sklearn(data, ARTIFACTS_FOLDER)\n",
    "train_xgboost(data, ARTIFACTS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396b609",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts\n",
    "\n",
    " * Here we create the Tempo models and orchestration Pipeline for our final service using our models.\n",
    " * For illustration the final service will call the sklearn model and based on the result will decide to return that prediction or call the xgboost model and return that prediction instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8345fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tempo import get_tempo_artifacts\n",
    "classifier, sklearn_model, xgboost_model = get_tempo_artifacts(ARTIFACTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0af26",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/tempo.py\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import Pipeline, PipelineModels\n",
    "from tempo.serve.utils import pipeline\n",
    "\n",
    "from .train import SKLearnFolder, XGBoostFolder\n",
    "\n",
    "PipelineFolder = \"classifier\"\n",
    "SKLearnTag = \"sklearn prediction\"\n",
    "XGBoostTag = \"xgboost prediction\"\n",
    "\n",
    "\n",
    "def get_tempo_artifacts(artifacts_folder: str) -> Tuple[Pipeline, Model, Model]:\n",
    "\n",
    "    sklearn_model = Model(\n",
    "        name=\"test-iris-sklearn\",\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=f\"{artifacts_folder}/{SKLearnFolder}\",\n",
    "        uri=\"s3://tempo/basic/sklearn\",\n",
    "    )\n",
    "\n",
    "    xgboost_model = Model(\n",
    "        name=\"test-iris-xgboost\",\n",
    "        platform=ModelFramework.XGBoost,\n",
    "        local_folder=f\"{artifacts_folder}/{XGBoostFolder}\",\n",
    "        uri=\"s3://tempo/basic/xgboost\",\n",
    "    )\n",
    "\n",
    "    @pipeline(\n",
    "        name=\"classifier\",\n",
    "        uri=\"s3://tempo/basic/pipeline\",\n",
    "        local_folder=f\"{artifacts_folder}/{PipelineFolder}\",\n",
    "        models=PipelineModels(sklearn=sklearn_model, xgboost=xgboost_model),\n",
    "    )\n",
    "    def classifier(payload: np.ndarray) -> Tuple[np.ndarray, str]:\n",
    "        res1 = classifier.models.sklearn(input=payload)\n",
    "\n",
    "        if res1[0] == 1:\n",
    "            return res1, SKLearnTag\n",
    "        else:\n",
    "            return classifier.models.xgboost(input=payload), XGBoostTag\n",
    "\n",
    "    return classifier, sklearn_model, xgboost_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a0525e",
   "metadata": {},
   "source": [
    "## Unit Tests\n",
    "\n",
    " * Here we run our unit tests to ensure the orchestration works before running on the actual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159cbec",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load tests/test_tempo.py\n",
    "import numpy as np\n",
    "from src.tempo import SKLearnTag, XGBoostTag, get_tempo_artifacts\n",
    "\n",
    "\n",
    "def test_sklearn_model_used():\n",
    "    classifier, _, _ = get_tempo_artifacts(\"\")\n",
    "    classifier.models.sklearn = lambda input: np.array([[1]])\n",
    "    res, tag = classifier(np.array([[1, 2, 3, 4]]))\n",
    "    assert res[0][0] == 1\n",
    "    assert tag == SKLearnTag\n",
    "\n",
    "\n",
    "def test_xgboost_model_used():\n",
    "    classifier, _, _ = get_tempo_artifacts(\"\")\n",
    "    classifier.models.sklearn = lambda input: np.array([[0.2]])\n",
    "    classifier.models.xgboost = lambda input: np.array([[0.1]])\n",
    "    res, tag = classifier(np.array([[1, 2, 3, 4]]))\n",
    "    assert res[0][0] == 0.1\n",
    "    assert tag == XGBoostTag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa78ec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.9, pytest-6.2.0, py-1.10.0, pluggy-0.13.1\n",
      "rootdir: /home/clive/work/mlops/fork-tempo, configfile: setup.cfg\n",
      "plugins: asyncio-0.14.0\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_tempo.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                   [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 1.03s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest tests/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc6a4b",
   "metadata": {},
   "source": [
    "## Save Classifier Environment\n",
    "\n",
    " * In preparation for running our models we save the Python environment needed for the orchestration to run as defined by a `conda.yaml` in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e1f9017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: tempo\r\n",
      "channels:\r\n",
      "  - defaults\r\n",
      "dependencies:\r\n",
      "  - python=3.7.9\r\n",
      "  - pip:\r\n",
      "    - mlops-tempo @ file:///home/clive/work/mlops/fork-tempo\r\n",
      "    - mlserver==0.3.1.dev7\r\n"
     ]
    }
   ],
   "source": [
    "!cat artifacts/classifier/conda.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c23ab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/clive/anaconda3/envs/tempo-6dae3aec-6d42-4871-a1cf-2816476a992c' to '/home/clive/work/mlops/fork-tempo/docs/examples/intro/artifacts/classifier/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 12.2s\n"
     ]
    }
   ],
   "source": [
    "from tempo.serve.loader import save\n",
    "save(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a21d5",
   "metadata": {},
   "source": [
    "## Test Locally on Docker\n",
    "\n",
    " * Here we test our models using production images but running locally on Docker. This allows us to ensure the final production deployed model will behave as expected when deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a36bfb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "docker_runtime = SeldonDockerRuntime()\n",
    "docker_runtime.deploy(classifier)\n",
    "docker_runtime.wait_ready(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb09a516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00847207, 0.03168793, 0.95984   ]], dtype=float32),\n",
       " 'xgboost prediction')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b22014e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output0': array([1.], dtype=float32), 'output1': 'sklearn prediction'}\n",
      "{'output0': array([[0.97329617, 0.02412145, 0.00258233]], dtype=float32), 'output1': 'xgboost prediction'}\n"
     ]
    }
   ],
   "source": [
    "print(classifier.remote(np.array([[0, 0, 0,0]])))\n",
    "print(classifier.remote(np.array([[5.964,4.006,2.081,1.031]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c6ea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime.undeploy(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91f4d7",
   "metadata": {},
   "source": [
    "## Production Option 1 (Deploy to Kubernetes with Tempo)\n",
    "\n",
    " * Here we illustrate how to run the final models in \"production\" on Kubernetes by using Tempo to deploy\n",
    " \n",
    " ### Prerequisites\n",
    " \n",
    " Create a Kind Kubernetes cluster with Minio and Seldon Core installed using Ansible from the Tempo project Ansible playbook.\n",
    " \n",
    " ```\n",
    " ansible-playbook ansible/playbooks/default.yaml\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8d2fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-secret created\r\n",
      "serviceaccount/tempo-pipeline created\r\n",
      "role.rbac.authorization.k8s.io/tempo-pipeline created\r\n",
      "rolebinding.rbac.authorization.k8s.io/tempo-pipeline-rolebinding created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f k8s/rbac -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa80565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.examples.minio import create_minio_rclone\n",
    "import os\n",
    "create_minio_rclone(os.getcwd()+\"/rclone.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39ff404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.loader import upload\n",
    "upload(sklearn_model)\n",
    "upload(xgboost_model)\n",
    "upload(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c56b5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import RuntimeOptions, KubernetesOptions\n",
    "runtime_options = RuntimeOptions(\n",
    "        k8s_options=KubernetesOptions(\n",
    "            namespace=\"production\",\n",
    "            authSecretName=\"minio-secret\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "363a9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "k8s_runtime = SeldonKubernetesRuntime(runtime_options)\n",
    "k8s_runtime.deploy(classifier)\n",
    "k8s_runtime.wait_ready(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8feb662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output0': array([1.], dtype=float32), 'output1': 'sklearn prediction'}\n",
      "{'output0': array([[0.00847207, 0.03168794, 0.95984   ]], dtype=float32), 'output1': 'xgboost prediction'}\n"
     ]
    }
   ],
   "source": [
    "print(classifier.remote(payload=np.array([[0, 0, 0, 0]])))\n",
    "print(classifier.remote(payload=np.array([[1, 2, 3, 4]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c789f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_runtime.undeploy(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7205b",
   "metadata": {},
   "source": [
    "## Production Option 2 (Gitops)\n",
    "\n",
    " * We create yaml to provide to our DevOps team to deploy to a production cluster\n",
    " * We add Kustomize patches to modify the base Kubernetes yaml created by Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69ee5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.serve.metadata import RuntimeOptions, KubernetesOptions\n",
    "runtime_options = RuntimeOptions(\n",
    "        k8s_options=KubernetesOptions(\n",
    "            namespace=\"production\",\n",
    "            authSecretName=\"minio-secret\"\n",
    "        )\n",
    "    )\n",
    "k8s_runtime = SeldonKubernetesRuntime()\n",
    "yaml_str = k8s_runtime.to_k8s_yaml(classifier)\n",
    "with open(os.getcwd()+\"/k8s/tempo.yaml\",\"w\") as f:\n",
    "    f.write(yaml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "748bd754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: machinelearning.seldon.io/v1\r\n",
      "kind: SeldonDeployment\r\n",
      "metadata:\r\n",
      "  name: classifier\r\n",
      "  namespace: production\r\n",
      "spec:\r\n",
      "  predictors:\r\n",
      "  - componentSpecs:\r\n",
      "    - spec:\r\n",
      "        containers:\r\n",
      "        - args: []\r\n",
      "          env:\r\n",
      "          - name: MLSERVER_HTTP_PORT\r\n",
      "            value: \"9000\"\r\n",
      "          - name: MLSERVER_GRPC_PORT\r\n",
      "            value: \"9500\"\r\n",
      "          - name: MLSERVER_MODEL_IMPLEMENTATION\r\n",
      "            value: tempo.mlserver.InferenceRuntime\r\n",
      "          - name: MLSERVER_MODEL_NAME\r\n",
      "            value: classifier\r\n",
      "          - name: MLSERVER_MODEL_URI\r\n",
      "            value: /mnt/models\r\n",
      "          - name: TEMPO_RUNTIME_OPTIONS\r\n",
      "            value: '{\"runtime\": null, \"docker_options\": {\"defaultRuntime\": \"tempo.seldon.SeldonDockerRuntime\"},\r\n",
      "              \"k8s_options\": {\"replicas\": 1, \"minReplicas\": null, \"maxReplicas\": null,\r\n",
      "              \"authSecretName\": null, \"serviceAccountName\": null, \"defaultRuntime\":\r\n",
      "              \"tempo.seldon.SeldonKubernetesRuntime\", \"namespace\": \"default\"}, \"ingress_options\":\r\n",
      "              {\"ingress\": \"tempo.ingress.istio.IstioIngress\", \"ssl\": false, \"verify_ssl\":\r\n",
      "              true}}'\r\n",
      "          image: seldonio/mlserver:0.3.1.dev7\r\n",
      "          name: classifier\r\n",
      "          resources:\r\n",
      "            limits:\r\n",
      "              cpu: 1\r\n",
      "              memory: 1Gi\r\n",
      "            requests:\r\n",
      "              cpu: 500m\r\n",
      "              memory: 500Mi\r\n",
      "    graph:\r\n",
      "      implementation: TRITON_SERVER\r\n",
      "      modelUri: s3://tempo/basic/pipeline\r\n",
      "      name: classifier\r\n",
      "      serviceAccountName: tempo-pipeline\r\n",
      "      type: MODEL\r\n",
      "    name: default\r\n",
      "    replicas: 1\r\n",
      "  protocol: kfserving\r\n",
      "---\r\n",
      "apiVersion: machinelearning.seldon.io/v1\r\n",
      "kind: SeldonDeployment\r\n",
      "metadata:\r\n",
      "  name: test-iris-sklearn\r\n",
      "  namespace: production\r\n",
      "spec:\r\n",
      "  predictors:\r\n",
      "  - graph:\r\n",
      "      implementation: SKLEARN_SERVER\r\n",
      "      modelUri: s3://tempo/basic/sklearn\r\n",
      "      name: test-iris-sklearn\r\n",
      "      type: MODEL\r\n",
      "    name: default\r\n",
      "    replicas: 1\r\n",
      "  protocol: kfserving\r\n",
      "---\r\n",
      "apiVersion: machinelearning.seldon.io/v1\r\n",
      "kind: SeldonDeployment\r\n",
      "metadata:\r\n",
      "  name: test-iris-xgboost\r\n",
      "  namespace: production\r\n",
      "spec:\r\n",
      "  predictors:\r\n",
      "  - graph:\r\n",
      "      implementation: XGBOOST_SERVER\r\n",
      "      modelUri: s3://tempo/basic/xgboost\r\n",
      "      name: test-iris-xgboost\r\n",
      "      type: MODEL\r\n",
      "    name: default\r\n",
      "    replicas: 1\r\n",
      "  protocol: kfserving\r\n"
     ]
    }
   ],
   "source": [
    "!kustomize build k8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc649c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
