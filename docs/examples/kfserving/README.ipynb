{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "statutory-comedy",
   "metadata": {},
   "source": [
    "# Introction to Tempo on Kubernetes\n",
    "\n",
    "This notebook will walk you through an end-to-end example deploying a Tempo pipeline deployed to Kubernetes.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebooks needs to be run in the `tempo-examples` conda environment defined below. Create from project root folder:\n",
    "\n",
    "```bash\n",
    "conda env create --name tempo-examples --file conda/tempo-examples.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-complaint",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "We will show two Iris dataset prediction models combined with service orchestration that shows some arbitrary python code to control predictions from the two models.\n",
    "\n",
    "![architecture](architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hydraulic-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-turning",
   "metadata": {},
   "source": [
    "## Train Iris Models\n",
    "\n",
    "We will train:\n",
    "\n",
    "  * A sklearn logistic regression model\n",
    "  * A xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eleven-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p artifacts/sklearn\n",
    "!mkdir -p artifacts/xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weekly-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # we only take the first two features.\n",
    "y = iris.target\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X, y)\n",
    "logreg.predict_proba(X[0:1])\n",
    "with open(\"./artifacts/sklearn/model.joblib\",\"wb\") as f:\n",
    "    joblib.dump(logreg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "innocent-shock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:21:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rskolasinski/miniconda3/envs/tempo-examples/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X,y)\n",
    "clf.save_model(\"./artifacts/xgboost/model.bst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-sheriff",
   "metadata": {},
   "source": [
    "## Defining pipeline\n",
    "\n",
    "The first step will be to define our custom pipeline.\n",
    "This pipeline will access 2 models, stored remotely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "appointed-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from tempo.serve.metadata import ModelFramework, KubernetesOptions, RuntimeOptions\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import PipelineModels\n",
    "from tempo.seldon.protocol import SeldonProtocol\n",
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "from tempo.kfserving.protocol import KFServingV2Protocol, KFServingV1Protocol\n",
    "from tempo.kfserving.k8s import KFServingKubernetesRuntime\n",
    "from tempo.serve.utils import pipeline, predictmethod\n",
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.serve.utils import pipeline\n",
    "from tempo.serve.loader import upload, save\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "SKLEARN_FOLDER = f\"{os.getcwd()}/artifacts/sklearn\"\n",
    "XGBOOST_FOLDER = f\"{os.getcwd()}/artifacts/xgboost\"\n",
    "PIPELINE_ARTIFACTS_FOLDER = f\"{os.getcwd()}/artifacts/classifier\"\n",
    "\n",
    "runtimeOptions=RuntimeOptions(  \n",
    "    k8s_options=KubernetesOptions( \n",
    "        defaultRuntime=\"tempo.kfserving.KFServingKubernetesRuntime\",\n",
    "        namespace=\"production\",\n",
    "        serviceAccountName=\"kf-tempo\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "sklearn_model = Model(\n",
    "    name=\"test-iris-sklearn\",\n",
    "    platform=ModelFramework.SKLearn,\n",
    "    protocol=KFServingV2Protocol(),\n",
    "    runtime_options=runtimeOptions,\n",
    "    local_folder=SKLEARN_FOLDER,\n",
    "    uri=\"s3://tempo/basic/sklearn\",\n",
    "    inputs=np.ndarray,\n",
    "    outputs=np.ndarray\n",
    ")\n",
    "\n",
    "xgboost_model = Model(\n",
    "    name=\"test-iris-xgboost\",\n",
    "    platform=ModelFramework.XGBoost,\n",
    "    protocol=KFServingV2Protocol(),\n",
    "    runtime_options=runtimeOptions,\n",
    "    local_folder=XGBOOST_FOLDER,\n",
    "    uri=\"s3://tempo/basic/xgboost\",\n",
    "    inputs=np.ndarray,\n",
    "    outputs=np.ndarray    \n",
    ")\n",
    "\n",
    "@pipeline(\n",
    "    name=\"classifier\",\n",
    "    uri=\"s3://tempo/basic/pipeline\",\n",
    "    local_folder=PIPELINE_ARTIFACTS_FOLDER,\n",
    "    runtime_options=runtimeOptions,\n",
    "    models=PipelineModels(sklearn=sklearn_model, xgboost=xgboost_model)\n",
    ")\n",
    "def classifier(payload: np.ndarray) -> Tuple[np.ndarray,str]:\n",
    "    res1 = classifier.models.sklearn(input=payload)\n",
    "    print(res1)\n",
    "    if res1[0] == 1:\n",
    "        return res1,\"sklearn prediction\"\n",
    "    else:\n",
    "        return classifier.models.xgboost(input=payload),\"xgboost prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-savage",
   "metadata": {},
   "source": [
    "### Saving artifacts\n",
    "\n",
    "We provide a conda yaml in out `local_folder` which tempo will use as the runtime environment to save. If this file was not there it would save the current conda environment. One can also provide a named conda environment with `conda_env` in the decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "subsequent-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PYTHON_VERSION = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "TEMPO_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coral-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate artifacts/classifier/conda.yaml\n",
    "name: tempo\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python={PYTHON_VERSION}\n",
    "  - pip:\n",
    "    - mlops-tempo @ file://{TEMPO_DIR}\n",
    "    - mlserver==0.3.1.dev7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tutorial-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Saving environment\n",
      "INFO:tempo:Saving tempo model to /home/rskolasinski/work/tempo/docs/examples/kfserving/artifacts/classifier/model.pickle\n",
      "INFO:tempo:Using found conda.yaml\n",
      "INFO:tempo:Creating conda env with: conda env create --name tempo-4ba01731-d002-4325-af4c-e27a844f7b1c --file /tmp/tmpr66ieu3k.yml\n",
      "INFO:tempo:packing conda environment from tempo-4ba01731-d002-4325-af4c-e27a844f7b1c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/rskolasinski/miniconda3/envs/tempo-4ba01731-d002-4325-af4c-e27a844f7b1c' to '/home/rskolasinski/work/tempo/docs/examples/kfserving/artifacts/classifier/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Removing conda env with: conda remove --name tempo-4ba01731-d002-4325-af4c-e27a844f7b1c --all --yes\n"
     ]
    }
   ],
   "source": [
    "save(classifier, save_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-machine",
   "metadata": {},
   "source": [
    "## Deploying pipeline to K8s\n",
    "\n",
    "The next step, will be to deploy our pipeline to Kubernetes.\n",
    "We will divide this process into 3 sub-steps:\n",
    "\n",
    "1. Save our artifacts and environment\n",
    "2. Upload to remote storage\n",
    "3. Deploy resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-domain",
   "metadata": {},
   "source": [
    "### Setup Namespace with Minio Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adolescent-presentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"production\" already exists\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "signal-upper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting auth.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile auth.yaml\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: minio-secret\n",
    "  annotations:\n",
    "     serving.kubeflow.org/s3-endpoint: minio.minio-system.svc.cluster.local:9000 # replace with your s3 endpoint\n",
    "     serving.kubeflow.org/s3-usehttps: \"0\" # by default 1, for testing with minio you need to set to 0\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: minioadmin\n",
    "  AWS_SECRET_ACCESS_KEY: minioadmin\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: kf-tempo\n",
    "secrets:\n",
    "- name: minio-secret\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: Role\n",
    "metadata:\n",
    "  name: kf-tempo\n",
    "rules:\n",
    "  - apiGroups:\n",
    "      - machinelearning.seldon.io\n",
    "    resources:\n",
    "      - seldondeployments/status\n",
    "    verbs:\n",
    "      - get\n",
    "  - apiGroups:\n",
    "      - serving.kubeflow.org\n",
    "    resources:\n",
    "      - inferenceservices/status\n",
    "    verbs:\n",
    "      - get\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: RoleBinding\n",
    "metadata:\n",
    "  name: tempo-pipeline-rolebinding\n",
    "roleRef:\n",
    "  apiGroup: rbac.authorization.k8s.io\n",
    "  kind: Role\n",
    "  name: kf-tempo\n",
    "subjects:\n",
    "  - kind: ServiceAccount\n",
    "    name: kf-tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thick-postcard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-secret configured\n",
      "serviceaccount/kf-tempo configured\n",
      "role.rbac.authorization.k8s.io/kf-tempo unchanged\n",
      "rolebinding.rbac.authorization.k8s.io/tempo-pipeline-rolebinding unchanged\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f auth.yaml -n production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-austria",
   "metadata": {},
   "source": [
    "### Uploading artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "molecular-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIO_IP=!kubectl get svc minio -n minio-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}'\n",
    "MINIO_IP=MINIO_IP[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "controversial-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate rclone.conf\n",
    "[s3]\n",
    "type = s3\n",
    "provider = minio\n",
    "env_auth = false\n",
    "access_key_id = minioadmin\n",
    "secret_access_key = minioadmin\n",
    "endpoint = http://{MINIO_IP}:9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "collaborative-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempo.conf import settings\n",
    "settings.rclone_cfg = os.getcwd() + \"/rclone.conf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "significant-literature",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Uploading /home/rskolasinski/work/tempo/docs/examples/kfserving/artifacts/sklearn to s3://tempo/basic/sklearn\n",
      "INFO:tempo:Uploading /home/rskolasinski/work/tempo/docs/examples/kfserving/artifacts/xgboost to s3://tempo/basic/xgboost\n",
      "INFO:tempo:Uploading /home/rskolasinski/work/tempo/docs/examples/kfserving/artifacts/classifier to s3://tempo/basic/pipeline\n"
     ]
    }
   ],
   "source": [
    "upload(sklearn_model)\n",
    "upload(xgboost_model)\n",
    "upload(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-retro",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pleasant-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_runtime = KFServingKubernetesRuntime()\n",
    "k8s_runtime.deploy(classifier)\n",
    "k8s_runtime.wait_ready(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-anxiety",
   "metadata": {},
   "source": [
    "### Sending requests\n",
    "\n",
    "Lastly, we can now send requests to our deployed pipeline.\n",
    "For this, we will leverage the `remote()` method, which will interact without our deployed pipeline (as opposed to executing our pipeline's code locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "editorial-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.utils import tempo_settings\n",
    "tempo_settings.remote_kubernetes(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ambient-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00847207, 0.03168794, 0.95984   ]], dtype=float32),\n",
       " 'xgboost prediction')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(payload=np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "extraordinary-shell",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Bad return code', 500, '  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/middleware/errors.py\", line 159, in __call__\\n    await self.app(scope, receive, _send)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/exceptions.py\", line 82, in __call__\\n    raise exc from None\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/exceptions.py\", line 71, in __call__\\n    await self.app(scope, receive, sender)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/routing.py\", line 566, in __call__\\n    await route.handle(scope, receive, send)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/routing.py\", line 227, in handle\\n    await self.app(scope, receive, send)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/routing.py\", line 41, in app\\n    response = await func(request)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/mlserver/rest/app.py\", line 24, in custom_route_handler\\n    return await original_route_handler(request)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/fastapi/routing.py\", line 202, in app\\n    dependant=dependant, values=values, is_coroutine=is_coroutine\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/fastapi/routing.py\", line 148, in run_endpoint_function\\n    return await dependant.call(**values)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/mlserver/rest/endpoints.py\", line 52, in infer\\n    return await self._data_plane.infer(payload, model_name, model_version)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/mlserver/handlers/dataplane.py\", line 56, in infer\\n    prediction = await model.predict(payload)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/mlserver.py\", line 16, in predict\\n    prediction = self._pipeline.request(payload.dict())\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/serve/base.py\", line 171, in request\\n    response = self._user_func(req_converted)\\n  File \"<ipython-input-5-f489942e0a56>\", line 63, in classifier\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/serve/base.py\", line 224, in __call__\\n    return self.remote(*args, **kwargs)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/serve/base.py\", line 195, in remote\\n    return remoter.remote(self.model_spec, *args, **kwargs)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/kfserving/k8s.py\", line 67, in remote\\n    endpoint, json=req, headers=headers, verify_ssl=model_spec.runtime_options.ingress_options.verify_ssl\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/requests/api.py\", line 119, in post\\n    return request(\\'post\\', url, data=data, json=json, **kwargs)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/requests/api.py\", line 61, in request\\n    return session.request(method=method, url=url, **kwargs)\\n')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4f8fb130fa38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/tempo/tempo/serve/base.py\u001b[0m in \u001b[0;36mremote\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mremoter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mremoter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRuntime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/tempo/tempo/kfserving/k8s.py\u001b[0m in \u001b[0;36mremote\u001b[0;34m(self, model_spec, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_protocol_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_details\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bad return code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mundeploy_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_spec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Bad return code', 500, '  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/middleware/errors.py\", line 159, in __call__\\n    await self.app(scope, receive, _send)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/exceptions.py\", line 82, in __call__\\n    raise exc from None\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/exceptions.py\", line 71, in __call__\\n    await self.app(scope, receive, sender)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/routing.py\", line 566, in __call__\\n    await route.handle(scope, receive, send)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/routing.py\", line 227, in handle\\n    await self.app(scope, receive, send)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/starlette/routing.py\", line 41, in app\\n    response = await func(request)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/mlserver/rest/app.py\", line 24, in custom_route_handler\\n    return await original_route_handler(request)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/fastapi/routing.py\", line 202, in app\\n    dependant=dependant, values=values, is_coroutine=is_coroutine\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/fastapi/routing.py\", line 148, in run_endpoint_function\\n    return await dependant.call(**values)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/mlserver/rest/endpoints.py\", line 52, in infer\\n    return await self._data_plane.infer(payload, model_name, model_version)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/mlserver/handlers/dataplane.py\", line 56, in infer\\n    prediction = await model.predict(payload)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/mlserver.py\", line 16, in predict\\n    prediction = self._pipeline.request(payload.dict())\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/serve/base.py\", line 171, in request\\n    response = self._user_func(req_converted)\\n  File \"<ipython-input-5-f489942e0a56>\", line 63, in classifier\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/serve/base.py\", line 224, in __call__\\n    return self.remote(*args, **kwargs)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/serve/base.py\", line 195, in remote\\n    return remoter.remote(self.model_spec, *args, **kwargs)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/tempo/kfserving/k8s.py\", line 67, in remote\\n    endpoint, json=req, headers=headers, verify_ssl=model_spec.runtime_options.ingress_options.verify_ssl\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/requests/api.py\", line 119, in post\\n    return request(\\'post\\', url, data=data, json=json, **kwargs)\\n  File \"/opt/mlserver/envs/environment/lib/python3.7/site-packages/requests/api.py\", line 61, in request\\n    return session.request(method=method, url=url, **kwargs)\\n')"
     ]
    }
   ],
   "source": [
    "classifier.remote(payload=np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.remote(payload=np.array([[5.964,4.006,2.081,1.031]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-fiber",
   "metadata": {},
   "source": [
    "### Undeploy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "statewide-match",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tempo:Undeploying classifier\n",
      "INFO:tempo:Undeploying test-iris-sklearn\n",
      "INFO:tempo:Undeploying test-iris-xgboost\n"
     ]
    }
   ],
   "source": [
    "k8s_runtime.undeploy(classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
