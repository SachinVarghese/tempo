{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef410d1",
   "metadata": {},
   "source": [
    "# Deploy to KFserving\n",
    "\n",
    "![architecture](architecture.png)\n",
    "\n",
    "In this introduction we will:\n",
    "\n",
    "  * [Describe the project structure](#Project-Structure)\n",
    "  * [Train some models](#Train-Models)\n",
    "  * [Create Tempo artifacts](#Create-Tempo-Artifacts)\n",
    "  * [Run unit tests](#Unit-Tests)\n",
    "  * [Save python environment for our classifier](#Save-Classifier-Environment)\n",
    "  * [Test Locally on Docker](#Test-Locally-on-Docker)\n",
    "  * [Production on Kubernetes via Tempo](#Production-Option-1-(Deploy-to-Kubernetes-with-Tempo))\n",
    "  * [Prodiuction on Kuebrnetes via GitOps](#Production-Option-2-(Gitops))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b5277",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebooks needs to be run in the `tempo-examples` conda environment defined below. Create from project root folder:\n",
    "\n",
    "```bash\n",
    "conda env create --name tempo-examples --file conda/tempo-examples.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ce5e8",
   "metadata": {},
   "source": [
    "## Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca70f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tree -P \"*.py\"  -I \"__init__.py|__pycache__\" -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dad4f",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "\n",
    " * This section is where as a data scientist you do your work of training models and creating artfacts.\n",
    " * For this example we train sklearn and xgboost classification models for the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c20ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempo.utils import logger\n",
    "import logging\n",
    "import numpy as np\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "ARTIFACTS_FOLDER = os.getcwd()+\"/artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2abd28",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/train.py\n",
    "from typing import Tuple\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "SKLearnFolder = \"sklearn\"\n",
    "XGBoostFolder = \"xgboost\"\n",
    "\n",
    "\n",
    "def load_iris() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data  # we only take the first two features.\n",
    "    y = iris.target\n",
    "    return (X, y)\n",
    "\n",
    "\n",
    "def train_sklearn(X: np.ndarray, y: np.ndarray, artifacts_folder: str):\n",
    "    logreg = LogisticRegression(C=1e5)\n",
    "    logreg.fit(X, y)\n",
    "    logreg.predict_proba(X[0:1])\n",
    "    with open(f\"{artifacts_folder}/{SKLearnFolder}/model.joblib\", \"wb\") as f:\n",
    "        joblib.dump(logreg, f)\n",
    "\n",
    "\n",
    "def train_xgboost(X: np.ndarray, y: np.ndarray, artifacts_folder: str):\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(X, y)\n",
    "    clf.save_model(f\"{artifacts_folder}/{XGBoostFolder}/model.bst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import IrisData\n",
    "from src.train import train_lr, train_xgb\n",
    "data = IrisData()\n",
    "\n",
    "train_lr(ARTIFACTS_FOLDER, data)\n",
    "train_xgb(ARTIFACTS_FOLDER, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396b609",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8345fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tempo import get_tempo_artifacts\n",
    "classifier, sklearn_model, xgboost_model = get_tempo_artifacts(ARTIFACTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0af26",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# %load src/tempo.py\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from src.constants import SKLearnFolder, XGBFolder, SKLearnTag, XGBoostTag\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import Pipeline, PipelineModels\n",
    "from tempo.serve.utils import pipeline\n",
    "\n",
    "\n",
    "def get_tempo_artifacts(artifacts_folder: str) -> Tuple[Pipeline, Model, Model]:\n",
    "    sklearn_model = Model(\n",
    "        name=\"test-iris-sklearn\",\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=f\"{artifacts_folder}/{SKLearnFolder}\",\n",
    "        uri=\"s3://tempo/basic/sklearn\",\n",
    "        description=\"SKLearn Iris classification model\",\n",
    "    )\n",
    "\n",
    "    xgboost_model = Model(\n",
    "        name=\"test-iris-xgboost\",\n",
    "        platform=ModelFramework.XGBoost,\n",
    "        local_folder=f\"{artifacts_folder}/{XGBFolder}\",\n",
    "        uri=\"s3://tempo/basic/xgboost\",\n",
    "        description=\"XGBoost Iris classification model\",\n",
    "    )\n",
    "\n",
    "    @pipeline(\n",
    "        name=\"classifier\",\n",
    "        uri=\"s3://tempo/basic/pipeline\",\n",
    "        local_folder=f\"{artifacts_folder}/classifier\",\n",
    "        models=PipelineModels(sklearn=sklearn_model, xgboost=xgboost_model),\n",
    "        description=\"A pipeline to use either an sklearn or xgboost model for Iris classification\",\n",
    "    )\n",
    "    def classifier(payload: np.ndarray) -> Tuple[np.ndarray, str]:\n",
    "        res1 = classifier.models.sklearn(input=payload)\n",
    "        print(res1)\n",
    "        if res1[0] == 1:\n",
    "            return res1, SKLearnTag\n",
    "        else:\n",
    "            return classifier.models.xgboost(input=payload), XGBoostTag\n",
    "\n",
    "    return classifier, sklearn_model, xgboost_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a0525e",
   "metadata": {},
   "source": [
    "## Unit Tests\n",
    "\n",
    " * Here we run our unit tests to ensure the orchestration works before running on the actual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159cbec",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load tests/test_deploy.py\n",
    "import numpy as np\n",
    "from src.tempo import get_tempo_artifacts\n",
    "from src.constants import SKLearnTag, XGBoostTag\n",
    "\n",
    "\n",
    "def test_sklearn_model_used():\n",
    "    classifier, _, _ = get_tempo_artifacts(\"\")\n",
    "    classifier.models.sklearn = lambda input: np.array([[1]])\n",
    "    res, tag = classifier(np.array([[1, 2, 3, 4]]))\n",
    "    assert res[0][0] == 1\n",
    "    assert tag == SKLearnTag\n",
    "\n",
    "\n",
    "def test_xgboost_model_used():\n",
    "    classifier, _, _ = get_tempo_artifacts(\"\")\n",
    "    classifier.models.sklearn = lambda input: np.array([[0.2]])\n",
    "    classifier.models.xgboost = lambda input: np.array([[0.1]])\n",
    "    res, tag = classifier(np.array([[1, 2, 3, 4]]))\n",
    "    assert res[0][0] == 0.1\n",
    "    assert tag == XGBoostTag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pytest tests/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc6a4b",
   "metadata": {},
   "source": [
    "## Save Classifier Environment\n",
    "\n",
    " * In preparation for running our models we save the Python environment needed for the orchestration to run as defined by a `conda.yaml` in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat artifacts/classifier/conda.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.loader import save\n",
    "save(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a21d5",
   "metadata": {},
   "source": [
    "## Test Locally on Docker\n",
    "\n",
    " * Here we test our models using production images but running locally on Docker. This allows us to ensure the final production deployed model will behave as expected when deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36bfb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "docker_runtime = SeldonDockerRuntime()\n",
    "docker_runtime.deploy(classifier)\n",
    "docker_runtime.wait_ready(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22014e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.remote(np.array([[0, 0, 0,0]])))\n",
    "print(classifier.remote(np.array([[5.964,4.006,2.081,1.031]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_runtime.undeploy(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91f4d7",
   "metadata": {},
   "source": [
    "## Production Option 1 (Deploy to Kubernetes with Tempo)\n",
    "\n",
    " * Here we illustrate how to run the final models in \"production\" on Kubernetes by using Tempo to deploy\n",
    " \n",
    "### Prerequisites\n",
    " \n",
    " Create a Kind Kubernetes cluster with Minio and KFserving installed using Ansible from the Tempo project Ansible playbook.\n",
    " \n",
    " ```\n",
    " ansible-playbook ansible/playbooks/kfserving.yaml\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create ns production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f k8s/rbac -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa80565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.examples.minio import create_minio_rclone\n",
    "import os\n",
    "create_minio_rclone(os.getcwd()+\"/rclone.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.loader import upload\n",
    "upload(sklearn_model)\n",
    "upload(xgboost_model)\n",
    "upload(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import RuntimeOptions, KubernetesOptions\n",
    "runtime_options=RuntimeOptions(  \n",
    "    k8s_options=KubernetesOptions( \n",
    "        defaultRuntime=\"tempo.kfserving.KFServingKubernetesRuntime\",\n",
    "        namespace=\"production\",\n",
    "        serviceAccountName=\"kf-tempo\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a9b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.kfserving.k8s import KFServingKubernetesRuntime\n",
    "k8s_runtime = KFServingKubernetesRuntime(runtime_options)\n",
    "k8s_runtime.deploy(classifier)\n",
    "k8s_runtime.wait_ready(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.remote(payload=np.array([[0, 0, 0, 0]])))\n",
    "print(classifier.remote(payload=np.array([[1, 2, 3, 4]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e8ca4",
   "metadata": {},
   "source": [
    "### Illustrate client using model remotely\n",
    "\n",
    "With the Kubernetes runtime one can list running models on the Kubernetes cluster and instantiate a RemoteModel to call the Tempo model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = k8s_runtime.list_models(namespace=\"production\")\n",
    "print(\"Name\\tDescription\")\n",
    "for model in models:\n",
    "    details = model.get_tempo().model_spec.model_details\n",
    "    print(f\"{details.name}\\t{details.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1903eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].remote(payload=np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_runtime.undeploy(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7205b",
   "metadata": {},
   "source": [
    "## Production Option 2 (Gitops)\n",
    "\n",
    " * We create yaml to provide to our DevOps team to deploy to a production cluster\n",
    " * We add Kustomize patches to modify the base Kubernetes yaml created by Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.kfserving.k8s import KFServingKubernetesRuntime\n",
    "k8s_runtime = KFServingKubernetesRuntime(runtime_options)\n",
    "yaml_str = k8s_runtime.to_k8s_yaml(classifier)\n",
    "with open(os.getcwd()+\"/k8s/tempo.yaml\",\"w\") as f:\n",
    "    f.write(yaml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bd754",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kustomize build k8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc649c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
