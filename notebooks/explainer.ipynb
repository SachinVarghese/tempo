{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import ModelFramework\n",
    "from tempo.serve.model import Model\n",
    "from tempo.seldon.docker import SeldonDockerRuntime\n",
    "from tempo.kfserving.protocol import KFServingV2Protocol\n",
    "from tempo.serve.utils import pipeline, predictmethod\n",
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.serve.metadata import ModelFramework, KubernetesOptions\n",
    "from alibi.utils.wrappers import ArgmaxTransformer\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import os \n",
    "import pprint\n",
    "import dill\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from alibi.explainers import AnchorTabular\n",
    "from alibi.datasets import fetch_adult\n",
    "\n",
    "adult = fetch_adult()\n",
    "data = adult.data\n",
    "target = adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map = adult.category_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data_perm = np.random.permutation(np.c_[data, target])\n",
    "data = data_perm[:,:-1]\n",
    "target = data_perm[:,-1]\n",
    "idx = 30000\n",
    "X_train,Y_train = data[:idx,:], target[:idx]\n",
    "X_test, Y_test = data[idx+1:,:], target[idx+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SKLearn Model and Alibi Anchors Tabular Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = [x for x in range(len(feature_names)) if x not in list(category_map.keys())]\n",
    "ordinal_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                      ('scaler', StandardScaler())])\n",
    "categorical_features = list(category_map.keys())\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', ordinal_transformer, ordinal_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features)])\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "model=Pipeline(steps=[(\"preprocess\",preprocessor),(\"model\",clf)])\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(Y_train, model.predict(X_train)))\n",
    "print('Test accuracy: ', accuracy_score(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import AnchorTabular\n",
    "predict_fn = lambda x: model.predict(x)\n",
    "explainer = AnchorTabular(predict_fn, feature_names, categorical_names=category_map, seed=1)\n",
    "explainer.fit(X_train, disc_perc=[25, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain(X_test[0], threshold=0.95)\n",
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('Coverage: %.2f' % explanation.coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(model, os.getcwd()+'/income_model/model.joblib') \n",
    "with open(os.getcwd()+\"/income_explainer/explainer.dill\", 'wb') as f:\n",
    "    dill.dump(explainer,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_options = KubernetesOptions(namespace=\"production\")\n",
    "k8s_runtime = SeldonKubernetesRuntime(k8s_options=k8s_options)\n",
    "\n",
    "sklearn_model = Model(\n",
    "        name=\"income-sklearn\",\n",
    "        runtime=SeldonDockerRuntime(),\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=os.getcwd()+\"/income_model\",\n",
    "        uri=\"gs://seldon-models/test/income/model\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@pipeline(name=\"income-explainer\",\n",
    "          runtime=SeldonDockerRuntime(protocol=KFServingV2Protocol()),\n",
    "          uri=\"gs://seldon-models/test/income/explainer\",\n",
    "          local_folder=os.getcwd()+\"/income_explainer\",\n",
    "          conda_env=\"tempo-test\",\n",
    "          models=[sklearn_model])\n",
    "class ExplainerPipeline(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        if \"MLSERVER_MODELS_DIR\" in os.environ:\n",
    "            models_folder = \"\"\n",
    "        else:\n",
    "            models_folder = \"/income_explainer\"\n",
    "        with open(os.getcwd()+models_folder+\"/explainer.dill\", \"rb\") as f:\n",
    "            self.explainer = dill.load(f)\n",
    "        self.ran_init = True\n",
    "        \n",
    "    def update_predict_fn(self, x):\n",
    "        if np.argmax(sklearn_model(x).shape) == 0:\n",
    "            self.explainer.predictor = sklearn_model\n",
    "            self.explainer.samplers[0].predictor = sklearn_model\n",
    "        else:\n",
    "            self.explainer.predictor = ArgmaxTransformer(sklearn_model)\n",
    "            self.explainer.samplers[0].predictor = ArgmaxTransformer(sklearn_model)\n",
    "\n",
    "    @predictmethod\n",
    "    def explain(self, payload: np.ndarray, parameters: dict) -> str:\n",
    "        print(\"Explain called with \", parameters)\n",
    "        if not self.ran_init:\n",
    "            print(\"Loading explainer\")\n",
    "            self.__init__()\n",
    "        self.update_predict_fn(payload)\n",
    "        print(\"calling explain\")\n",
    "        explanation = self.explainer.explain(payload, **parameters)\n",
    "        return explanation.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model to Docker and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.deploy()\n",
    "sklearn_model.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96, 0.04]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model(X_test[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create explainer and test against model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ExplainerPipeline() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(save_env=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain called with  {'threshold': 0.99}\n",
      "calling explain\n",
      "['Relationship = Unmarried', 'Sex = Female', 'Capital Gain <= 0.00', 'Capital Loss <= 0.00']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(p.explain(X_test[0:1], {\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save environment and deploy explainer to docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.deploy()\n",
    "p.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create v2 from any\n",
      "['Relationship = Unmarried', 'Sex = Female', 'Capital Gain <= 0.00', 'Marital Status = Separated']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(p.remote(payload=X_test[0:1], parameters={\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy to production on Kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "k8s_options = KubernetesOptions(namespace=\"production\")\n",
    "k8s_runtime = SeldonKubernetesRuntime(k8s_options=k8s_options)\n",
    "k8s_runtime_v2 = SeldonKubernetesRuntime(k8s_options=k8s_options, protocol=KFServingV2Protocol())\n",
    "\n",
    "sklearn_model.set_runtime(k8s_runtime)\n",
    "p.set_runtime(k8s_runtime_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save(save_env=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.upload()\n",
    "p.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.deploy()\n",
    "p.wait_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create v2 from any\n",
      "['Relationship = Unmarried', 'Capital Gain <= 0.00', 'Sex = Female', 'Marital Status = Separated', 'Education = Associates', 'Capital Loss <= 0.00']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(p.remote(payload=X_test[0:1], parameters={\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.undeploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: machinelearning.seldon.io/v1\n",
      "kind: SeldonDeployment\n",
      "metadata:\n",
      "  name: income-explainer\n",
      "  namespace: production\n",
      "spec:\n",
      "  predictors:\n",
      "  - componentSpecs:\n",
      "    - spec:\n",
      "        containers:\n",
      "        - args: []\n",
      "          env:\n",
      "          - name: MLSERVER_HTTP_PORT\n",
      "            value: '9000'\n",
      "          - name: MLSERVER_GRPC_PORT\n",
      "            value: '9500'\n",
      "          - name: MLSERVER_MODEL_IMPLEMENTATION\n",
      "            value: mlserver_tempo.TempoModel\n",
      "          - name: MLSERVER_MODEL_NAME\n",
      "            value: income-explainer\n",
      "          - name: MLSERVER_MODEL_URI\n",
      "            value: /mnt/models\n",
      "          image: seldonio/mlserver:0.3.1.dev5\n",
      "          name: income-explainer\n",
      "    graph:\n",
      "      implementation: TRITON_SERVER\n",
      "      modelUri: gs://seldon-models/test/income/explainer\n",
      "      name: income-explainer\n",
      "      serviceAccountName: tempo-pipeline\n",
      "      type: MODEL\n",
      "    name: default\n",
      "    replicas: 1\n",
      "  protocol: kfserving\n",
      "\n",
      "---\n",
      "apiVersion: machinelearning.seldon.io/v1\n",
      "kind: SeldonDeployment\n",
      "metadata:\n",
      "  name: income-sklearn\n",
      "  namespace: production\n",
      "spec:\n",
      "  predictors:\n",
      "  - graph:\n",
      "      implementation: SKLEARN_SERVER\n",
      "      modelUri: gs://seldon-models/test/income/model\n",
      "      name: income-sklearn\n",
      "      type: MODEL\n",
      "    name: default\n",
      "    replicas: 1\n",
      "  protocol: seldon\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yaml = p.to_k8s_yaml()\n",
    "print (eval(pprint.pformat(yaml)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
